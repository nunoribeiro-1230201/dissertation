\chapter{State of the art} % Main chapter title

%-------------------------------------------------------------------------------
%---------
%
\section{Research Questions}

For the literature review and the state of the art analysis, two research questions have been formulated to address the essential background and focus of this dissertation. The first research question centers on the fault tolerance mechanisms of each language under study. The second research question examines the benchmarking strategies that simulate distributed systems, including microservices, and identifies the metrics necessary to measure the fault tolerance aspects.

\begin{itemize}
    \item \textbf{RQ1:} How do the programming languages Elixir, Scala with Akka, and Go implement fault tolerance mechanisms in distributed systems, and what are the comparative strengths, weaknesses, and trade-offs of each approach?
    \item \textbf{RQ2:} What are the most effective benchmarking strategies for simulating distributed environments, and which metrics are most relevant for evaluating fault tolerance in these scenarios?
\end{itemize}

\subsection{Research Methodology}

This section outlines the research methodology adopted in this dissertation. It is important to note that this study addresses, to the best of our knowledge, a gap in the literature regarding a direct comparison of fault tolerance mechanisms in the programming languages Elixir, Scala with Akka, and Go. To the best of our knowledge, no prior study has evaluated these three languages side-by-side in fault tolerance test scenarios.

However, relevant work can be found in the study by Valkov et al. \cite{Valkov2018}, which compared Erlang, Go, and Scala in terms of \gls{IPC} latency, process creation time, the maximum number of supported processes, and throughput. This work serves as a valuable reference, but it does not delve into fault tolerance test scenarios, which this dissertation seeks to address.

To explore the existing body of knowledge and identify studies relevant to the three programming languages, searches were conducted in major academic databases, specifically IEEE Xplore and ACM Digital Library. The objective was to find articles that included the three languages in their titles, allowing for Erlang to be considered in place of Elixir. The search was initiated with a starting date of 2013, coinciding with the publication of the second edition of Joe Armstrong's book on Erlang. However, the search yielded no results in the IEEE Xplore database, while the ACM Digital Library returned only two articles, ultimately filtering down to the work by Valkov et al. By modifying the query to search for the same language name but across all metadata, it was identified 13 articles in the ACM Digital Library. Among these, only the work of Valkov et al. \cite{Valkov2018} is relevant.

\textbf{IEEE Xplore Query:}
\begin{verbatim}
"query": { 
    ("Document Title": "Elixir" OR "Document Title": "Erlang") AND
    ("Document Title": "Go" OR "Document Title": "Golang") AND 
    ("Document Title": "Akka" OR "Document Title": "Scala") 
}
\end{verbatim}


\textbf{ACM Digital Library Query:}
\begin{verbatim}
"query": { 
    Title:((Elixir OR Erlang) AND (Go OR Golang)) 
}
"filter": {
     E-Publication Date: (01/01/2013 TO 12/31/2024), ACM Content: DL 
}
\end{verbatim}


\textbf{RQ1: How do the programming languages Elixir, Scala with Akka, and Go implement fault tolerance mechanisms in distributed systems, and what are the comparative
    strengths, weaknesses, and trade-offs of each approach?}

Given the scope of the research question, developing a research strategy that yields precise and relevant results it challenging. Fault tolerance is a broad subject, spanning diverse areas from hardware to electronic devices until critical systems. Moreover, the programming languages under study are employed in varied contexts, such as Elixir’s popularity in \gls{IoT} and Go’s extensive use in microservices, at the same time being general purpose languages used in diverse areas. This diversity introduces complexity when conducting research queries, resulting in an huge volume of information on a wide range of topics, or the lack of results in a more narrow query like the following one, that contains the important keywords for the work:

\begin{verbatim}
"query": { 
    Abstract:(
        ("fault tolerance" OR "error handling" OR "resilience") AND
        ("distributed systems" OR "microservices" OR "software") AND 
        ("Elixir" OR "Scala" OR "Akka" OR "Go" OR "Golang" OR "Erlang")
    )
}
\end{verbatim}

To address this problem, the methodology employed covered grey literature, particularly books, due to their mature, structured content. Books provide comprehensive insights into foundational principles, and given that the evolution of programming languages tends to be gradual, they serve as reliable resources for understanding their core concepts and implementations, taking in consideration the choose of recently books. At the same time, white literature, including academic papers and recent articles, was included to capture the latest advancements, structures, and innovations within these languages.

Given the technical and practical focus of the study, a more ad-hoc research approach was adopted, like searching on the academic databases for more focused themes, not systematic queries or keywords. Official documentation for each language it was also consulted, as it provides up-to-date information directly from the creators. Furthermore, trusted blogs and community resources were consulted in order to utilize the collective knowledge and practical experiences of developers, which often provide valuable insight that may not be addressed elsewhere.

\textbf{RQ2: What are the most effective benchmarking strategies for simulating distributed environments, and which metrics are most relevant for evaluating fault tolerance in these scenarios?}

...

\section{Elixir Programming Language Analysis}

The following sections provide an overview of Elixir and its foundational principles within the Erlang ecosystem. This discussion will explore how the ecosystem relates to Elixir's modernization and how it enhances fault tolerance. Additionally, the fault tolerance strategies employed within this ecosystem will be examined, including their drawbacks and real-world applications, such as third-party libraries.

\subsection{The Foundation of Erlang}

Elixir is built on top of Erlang, making it essential to first understand Erlang’s core principles and environment to move into Elixir’s capabilities. Elixir leverages Erlang’s foundation for constructing fault-tolerant and distributed systems, benefiting from its mature ecosystem and proven reliability \cite{Juric2024,Armstrong2013}.

Erlang, developed in the mids of 1980s by Ericsson, was specifically designed to support systems that are highly reliable, responsive, scalable, and always available \cite{Armstrong2013,Juric2024}. Over the years, Erlang has evolved significantly, and Elixir represents a major milestone in this environment's evolution. Elixir enhances the ecosystem with modern features, such as a more developer-friendly syntax, powerful metaprogramming capabilities with macros, and improved tooling, all while maintaining full compatibility with the Erlang runtime \cite{Juric2024}. This success is closely tied to its coupling with Erlang’s semantics, also the inclusion of the \gls{OTP}, which provides robust libraries and tools. Additionally, Elixir inherits the power of \gls{BEAM}, the Erlang \gls{VM}, which could be considered as a state of art concurrent programming model \cite{erlang-concurrency-blog}.

\subsubsection{Concurrency in BEAM}

Concurrency is one of the most defining aspects of the Erlang environment, earning it the title of being a concurrency oriented language by many. At the heart of this model are processes, which adhere to the Actor Model \cite{Juric2024,Valkov2018}. In this paradigm, each process acts as an independent actor, being lightweight and isolated, communicating with others through message-passing via mailboxes. These processes differ from heavyweight \gls{OS} processes or threads, which rely heavily on the \gls{OS} for management and lack the flexibility needed for optimizations. For instance, in the \gls{JVM}, platform threads are a thin abstraction over \gls{OS} threads, limiting control and optimization due to the fact of \gls{OS} threads are heavy. However, virtual threads, introduced on Java 21, brings more capabilities to the \gls{JVM} allowing a more fined scheduler like BEAM does, but in a less adoption for now \cite{erlang-concurrency-blog}.

In contrast, the \gls{BEAM} virtual machine employs a concurrency-oriented programming model, where a single thread per \gls{CPU} core manages numerous lightweight processes. This architecture enables \gls{BEAM} to effectively handle parallelism by assigning one scheduler per \gls{CPU} to oversee multiple lightweight processes. This approach is illustrated in Figure \ref{fig:beam-process}, which demonstrates how this architecture facilitates fault tolerance through process isolation. In the figure, the \gls{BEAM} thread is shown alongside all associated processes, with each process linked to a scheduler, which in turn is connected to a \gls{CPU} \cite{Juric2024}.


\begin{figure}
    \centering
    \frame{\includegraphics[width=120mm]{ch-state/assets/beam-process.png}}
    \caption[Concurrency in the Erlang virtual machine]{Concurrency in the Erlang virtual machine \cite{Juric2024}.}
    \label{fig:beam-process}
\end{figure}

The \gls{BEAM} scheduler is considered preemptive, meaning that assigns short execution time slices to each process. This ensures that long-running tasks do not monopolize system resources, promoting fairness and responsiveness \cite{Armstrong2013}. Also, it promotes fault tolerance characteristic by stopping processes carried with permanent faults, where on a non-preemptive scheduler could harm the overall system. Processes that are blocked due to I/O operations or waiting for messages are efficiently managed by separate threads or a kernel polling service, preventing unnecessary CPU usage and ensuring that waiting processes do not stop the execution of others \cite{Juric2024,erlang-concurrency-blog}.

\begin{figure}
    \centering
    \includegraphics[width=120mm]{ch-state/assets/elixir-vs-jvm-threads.png}
    \caption[Elixir/BEAM processes vs JVM threads]{Elixir/BEAM processes vs JVM threads \cite{erlang-concurrency-blog}.}
    \label{fig:beam-vs-jvm}
\end{figure}

In a direct comparison of Elixir’s processes running on \gls{BEAM} with the two threading techniques of the \gls{JVM} \cite{erlang-concurrency-blog}, as illustrated in Figure \ref{fig:beam-vs-jvm}, notable differences appears. Under low load conditions, all three strategies, Elixir’s lightweight processes, the \gls{JVM}’s platform, and virtual threads, perform effectively. However, as the system approaches the stability limits of platform threads, approximately 2500 concurrent units, Elixir continues to handle additional processes, scaling up to approximately 200,000 concurrent processes. Although the per-task completion time increases slightly under such high loads, the system remains operational and stable. The opposite occurs with both \gls{JVM} techniques, resulting in an overload that makes maintaining pace impossible. Furthermore, \gls{BEAM} imposes a theoretical limit of roughly 134 millions processes, where this limit are lowered where the underlying implementation are a direct relationship with \gls{OS} threads, like what happens in \gls{JVM} \cite{Juric2024}. The approximate minimum size of a process is more less than one kilobyte.

This scalability advantage can be attributed to the architecture of the underlying \gls{BEAM}. Unlike the \gls{JVM}, which relies on a shared heap and tightly integrates with \gls{OS} threads. However, the \gls{JVM} threading model is better suited for low-concurrency scenarios involving long-lived threads. In contrast, Elixir/\gls{BEAM} excels in high-concurrency situations with short-lived processes \cite{erlang-concurrency-blog, Valkov2018}.

\subsubsection{Garbage Collection and Immutability}

Erlang and Elixir enforce immutability as a fundamental principle, ensuring that all data remains unchangeable. This eliminates many common concurrency issues in systems with shared memory, such as race conditions \cite{Valkov2018}. Instead of sharing memory, processes communicate by passing immutable data. When a message is sent, the receiving process creates a copy of the data in its stack, eliminating the need for semaphore controls or similar synchronization mechanisms \cite{Juric2024,erlang-concurrency-blog}.

Because processes are completely isolated and do not share memory, \gls{BEAM} can execute garbage collection at the process level. This per-process garbage collection allows the \gls{VM} to reclaim memory for a single process without pausing the entire system, unlike the global garbage collection approach commonly used in the \gls{JVM}, where all processes share a single heap. Additionally, \gls{BEAM} optimizes garbage collection by focusing on individual schedulers enhancing its efficiency \cite{Armstrong2013,Juric2024}.

The garbage collector can significantly impact the performance of both the \gls{BEAM} and \gls{JVM}. As illustrated in Figure \ref{fig:beam-vs-jvm}, the load on \gls{BEAM} outperforms that of the \gls{JVM}. This difference may be attributed to the \gls{JVM}'s "stop-the-world" garbage collection, which can create performance bottlenecks. In contrast, \gls{BEAM} utilizes a more targeted garbage collection approach, benefiting from process isolation, which can lead to enhanced performance \cite{Valkov2018, Juric2024}.

\subsubsection{Hot-code swapping}

Hot-code swapping is a beneficial feature for building fault-tolerant systems, allowing the modification of code that is actively running in real time. This mechanism enhances fault tolerance by enabling the replacement of fault code without requiring system downtime. The process is typically achieved by sending a message to the server, which then handles the exchange \cite{Armstrong2013}.

It is important to note that this capability is not implemented in the same way on the \gls{JVM}. While the \gls{JVM} supports class reloading, it is not comparable to hot-code swapping of \gls{BEAM} and introduces significant complexities, such as managing already instantiated objects. In contrast, the hot-code swapping mechanism in systems that rely on \gls{BEAM} allow targeted changes, focused on specific parts without disrupting the system \cite{erlang-concurrency-blog}. Furthermore, in comparison with the Go language, which is a compiled language, does not permit hot code swapping in a production environment natively \cite{go-docs}.

\subsection{Fault Tolerance Mechanism and Strategies}

Elixir's fault tolerance strategies and mechanisms are associated to the Erlang ecosystem, leveraging the features of the \gls{BEAM}. A fundamental aspect of Elixir's fault tolerance is its adherence to the "let it crash" philosophy, which, combined with the Actor Model and extensive support from third-party tools, enhances its resilience. This is elaborated upon in the following sections.

\subsubsection{Let It Crash Philosophy and Actor Model}

Elixir inherits the “let it crash” philosophy from Erlang, which forms the foundation of its fault tolerance strategy. This philosophy is based on the principle that failures are unavoidable in distributed systems, and the optimal approach is not to prevent them entirely but to design systems that can recover autonomously and gracefully \cite{Armstrong2013, Kleppmann2017}. Instead of defensive programming to anticipate every potential error, Elixir encourages developers to isolate processes so that faults can occur without compromise the stability of the entire system \cite{Juric2024}.

The Actor Model plays a central role in achieving this resilience. In Elixir, lightweight processes act as independent actors that do not share memory and communicate exclusively through message-passing. When a process encounters an unrecoverable error, it is allowed to fail and terminate. This termination is both deliberate and beneficial, as it enables easy fault detection and ensures that failures do not propagate, preserving the integrity of the overall system \cite{Juric2024,Armstrong2013}. This model naturally integrates with the supervisor pattern, which is one of Elixir’s primary mechanisms for fault recovery.

\textit{\underline{Supervisor Pattern}}

The supervisor pattern is a practical implementation of the “let it crash” philosophy, built on the Actor Model. While the concept is not exclusive to Elixir, other frameworks like Akka also use it. Elixir leverage this pattern to build fault-tolerant systems \cite{Valkov2018}. In this approach, processes are classified into two types \cite{Juric2024}:

\begin{itemize}
    \item \textbf{Workers:} Processes that perform tasks or contain application logic but do not oversee other processes.
    \item \textbf{Supervisors:} Processes responsible for monitoring and managing other processes.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{ch-state/assets/supervisor-design.jpg}
    \caption[Supervisor tree pattern]{Supervisor tree pattern \cite{Juric2024}.}
    \label{fig:supervisor-pattern}
\end{figure}

Supervisors are organized into a hierarchical supervision tree, as illustrated in Figure \ref{fig:supervisor-pattern}. This tree defines the relationships between supervisors and workers, with each supervisor manage a group of processes. This structure provides modularity and ensures that fault recovery is localized, reducing the impact of failures \cite{Armstrong2013}.

Supervisors in Elixir, as well as in the supervisor pattern used in other frameworks, employ restart strategies to manage failures effectively. The options provided by the \gls{OTP} supervisors, which are among the most commonly used, include the following \cite{elixir-docs-hexdocs,Juric2024,Armstrong2013}:

\begin{itemize}
    \item \textbf{One-for-One:} If a single worker process fails, the supervisor restarts only that process.
    \item \textbf{One-for-All:} If one process fails, the supervisor restarts all processes it manages.
    \item \textbf{Rest-for-One:} If a process fails, the supervisor restarts it and all other processes started after it in the hierarchy.
\end{itemize}

Each restart strategy addresses specific use cases. Additionally, supervisors can enforce restrictions on the restart process through a restart frequency configuration. This mechanism monitors the frequency of the worker process failures within a specified time frame. If a worker process fails repeatedly and exceeds the configured threshold, the supervisor itself terminates to avoid harming the system or entering an infinite restart loop \cite{Armstrong2013}.

The One-for-One strategy is best suited for independent processes \cite{Armstrong2013}. For instance, in a web server handling multiple concurrent requests, this strategy could allow for the rapid recovery of a single failed process without affecting others. In contrast, the One-for-All strategy is ideal for tightly coupled processes \cite{Armstrong2013}. When one process fails, all other processes under the same supervisor are restarted, this could be useful for processes that need synchronization among them. Finally, the Rest-for-One strategy could be used in workflows with sequential dependencies \cite{elixir-docs-hexdocs}. For example, in a data pipeline where each stage relies on the output of the previous stage, a failure in one process triggers the restart of the failed process along with any subsequent ones.

The supervision pattern is not uniquely associated with Elixir, it is also used in other languages that follow the Actor Model, as well as in various frameworks that implement this programming style. One of the most notable \gls{JVM} frameworks is Akka \cite{akka-docs}. Additionally, in other paradigms such as Go, there are libraries capable of unifying \gls{CSP} with the Actor Model, such as the Proto-Actor\footnote{Proto-Actor: \url{https://proto.actor/} (accessed 4 December 2024)} library \cite{proto-actor-docs}. Both are described at the flow of this document.

\subsubsection{Tools and Support}

Elixir’s state of art in the fault tolerance area is related to the integration with the Erlang ecosystem, the \gls{BEAM}, the Actor Model, and the “let it crash” philosophy. These elements are further enhanced by Elixir’s compatibility with the \gls{OTP}, which provides a suite of design principles and tools for building fault-tolerant and distributed systems. This integration allows Elixir inherit and extend the mechanisms that have been tested and proven in real case scenarios \cite{Juric2024,Armstrong2013}.

The \gls{OTP} framework enables Elixir to use the supervision tree pattern, an important element on fault tolerance like described early. By combining the supervision tree with tools like GenServer, Elixir simplifies the management of stateful processes, facilitates concurrent operations, and ensures the efficient handling of asynchronous message passing \cite{elixir-docs-hexdocs}.

Additionally, \gls{OTP} supports features like hot-code swapping, enabling systems to update running code in real-time without downtime. The inclusion of the Mnesia distributed database within \gls{OTP} further strengthens Elixir’s fault tolerance capabilities. Mnesia allows state storage across distributed nodes, ensuring data consistency and availability even in the presence of node failures \cite{elixir-docs-hexdocs,elixir-school}.

Beyond the core features of \gls{OTP}, Elixir also includes Mix, a build tool that simplifies dependency management, testing, project configuration, and documentation generation. Mix integrates into the Elixir ecosystem, simplifying development workflows and contributing to the reliability of applications by ensuring consistent builds\cite{elixir-docs-hexdocs,elixir-school}.

In addition to the built-in capabilities of \gls{OTP}, Elixir’s ecosystem benefits from third-party projects that extend its fault-tolerant capabilities. For instance, Graft, developed by Le Brun et al. \cite{LeBrun2021} in 2019, and Ra\footnote{Ra: \url{https://github.com/rabbitmq/ra/} (accessed 4 December 2024)}, developed by the RabbitMq team, provide an implementation of the Raft consensus algorithm. Similarly, the Fuse\footnote{Fuse: \url{https://github.com/jlouis/fuse/} (accessed 4 December 2024)} library,
a widely-used implementation of the Circuit Breaker pattern, developed in Erlang, is also compatible with Elixir.

Another aspect of Elixir that is important to reference is its metaprogramming capabilities through macros, which allow developers to write code that generates code. This enables the Elixir codebase to be partially constructed using its own macros, extending the language's functionality and reducing boilerplate \cite{Juric2024}.

Lastly, it's important to mention the Elixir environment, which includes frameworks that enhance software development. Phoenix\footnote{Phoenix: \url{https://phoenixframework.org/} (accessed 4 December 2024)} is a popular framework for building scalable web applications. It inherits Elixir's fault tolerance, allowing applications to handle errors gracefully and maintain uptime. Phoenix also supports real-time features through channels for live updates \cite{Juric2024}. Nerves\footnote{Nerves: \url{https://nerves-project.org/} (accessed 4 December 2024)} focuses on embedded systems, leveraging Elixir's fault tolerance to create resilient IoT devices. It simplifies firmware development and management, ensuring efficient hardware and system updates while addressing fault tolerance concerns.

These integrations, extensions  demonstrate Elixir’s ability to not only leverage the proven robustness of \gls{OTP} but also adapt and grow through innovative tools and libraries, solidifying its position as a leading choice for building fault-tolerant, distributed applications.

\subsection{Drawbacks and Real Applications}

The benefits of Elixir are closely tied to the powerful features of the \gls{BEAM}, as mentioned earlier. However, there are some drawbacks to consider. One major limitation is the lack of third-party libraries, despite \gls{OTP} providing good support. Currently, it is challenging for Elixir to compete with more popular languages in this regard, like Java. Additionally, although the \gls{BEAM} has a distributed nature, its single-threaded architecture with a garbage collector makes it less suitable for fault-tolerant applications in critical systems that require fault tolerance at low level \cite{Juric2024}. Another potential drawback of Elixir is that it is a dynamically-typed programming language, which can result in errors from type mismatches or programming mistakes \cite{Cassola2020}. In contrast, languages such as Scala, Java, and Go offer advantages in this regard due to their static typing. However, there have been efforts to introduce a type system to Elixir without sacrificing the language's inherent dynamism, as demonstrated in the work of Cassola et al. \cite{Cassola2020}. Despite these efforts, the proposed type system has yet to gain widespread industry adoption.

Despite these limitations, Elixir has been successfully utilized in numerous prominent projects. Taking as reference the official website of Elixir, for example, Discord relies on Elixir as the backbone of its chat infrastructure, leveraging its ability to handle real-time communication effectively. PepsiCo also employs Elixir in a central role within its data pipeline, providing marketing and sales teams with tools to query, analyze, and integrate data from various search marketing partners. Other notable examples of Elixir's application include Heroku, SparkMeter, and several others.

\section{Scala Programming Language with Akka Toolkit Analysis}

The success of the Actor Model, particularly through its implementation in Erlang inspired other programming languages to replicate its concepts \cite{Juric2024,Abraham2023}. Among these were languages running on the \gls{JVM}, such as Scala and Java. However, significant differences emerged due to the JVM’s inherent concurrency challenges. Unlike \gls{BEAM}, which was built with lightweight process isolation and message passing at its core, the \gls{JVM} relied on low-level thread management and shared memory, necessitating careful synchronization through locks and other mechanisms \cite{Abraham2023,Valkov2018}. Although this languages offered \gls{API}s for concurrency management, these general-purpose languages placed much of the responsibility on the developer \cite{Abraham2023,akka-docs}, going against the philosophy of Erlang/Elixir, that it was created for easy concurrency programming.

This gap on the \gls{JVM} led to the creation of the Akka toolkit, designed to bring the actor programming model to its ecosystem. Inspired by Erlang, Akka offers a runtime and comprehensive tools to support actor-based programming, enabling developers to leverage the \gls{JVM} while benefiting from a more structured approach to concurrency \cite{akka-docs}. By abstracting thread management and offering a framework for distributed communication and fault tolerance, Akka provides a robust solution for building scalable and distributed systems. This capability is comparable to what Elixir offers \cite{Abraham2023}, while also leveraging the constraints and advantages of the underlying JVM.

\subsection{How Akka Handles the Actor Model}

This section examines two key characteristics of the actor model and how the Akka toolkit addresses them. Specifically, it focuses on the distributed nature and communication aspects of the model, as well as the isolation that Akka provides. The Akka toolkit serves as an abstraction layer built on top of Scala and the \gls{JVM}, facilitating the implementation of these principles in a robust and efficient manner.

\subsubsection{Location Transparency and Communication}

The Actor Model, like described before, defines a concurrent paradigm where actors operate independently, maintain their own mailboxes, and communicate exclusively via message passing. This communication should ideally respect the location transparent characteristic of distributed systems, allowing actors to interact seamlessly regardless of their physical location \cite{Armstrong2013}. On the JVM, threading enables scaling within a single machine by utilizing additional CPUs and memory due to the shared heap memory and concurrency model \cite{Abraham2023}. However, native support for scaling across distributed systems is lacking, a contrast to BEAM’s distributed aspect.

Elixir facilitates communication natively, with the Erlang distribution protocol \cite{elixir-school}. Akka addresses this limitation through its latest remoting protocol, Artery, which builds upon the older remoting mechanisms making improvements \cite{akka-docs,Abraham2023}. Artery employs either \gls{TCP} or Aeron UDP for communication. While Aeron UDP delivers high throughput and low latency, it lacks encryption, making it suitable for specific trusted environments. \gls{TCP}, on the other hand, offers encrypted communication with similarly high throughput, although with potentially higher latency under extreme load \cite{akka-docs}.

Akka facilitates scalability and communication with the discovery module. The discovery module serves a purpose similar to namespaces in Elixir, allowing actors to be registered with a specific name. In this context, actors can be registered using a designated key \cite{Abraham2023}, and other actor can communicate with that name without knowing the specific address. Furthermore, communication with these actors occurs through their mailboxes, following a standard First-In-First-Out (FIFO) protocol, equals to the behavior in Elixir \cite{Moamen2027,Juric2024}.

\subsubsection{Actors Isolation}

Actor isolation is a foundational principle of the Actor Model, where actors are designed to operate independently and avoid shared state \cite{Armstrong2013}. In Java, this independence can be implemented using low-level concurrency mechanisms, while in Scala it is often achieved through immutability. However, Akka significantly simplifies the process by providing an Actor API that inherently enforces isolation \cite{Abraham2023,Bagherzadeh2020}. Initially, Akka introduced the Classic Actors API, which supported untyped actor logic. In this model, messages were transmitted without type safety and processed using pattern matching, similar to the approach employed in Elixir \cite{akka-docs}. In contrast, the modern standard is the Typed Actor API, which provides a more robust and type-safe solution. The Typed Actor API enforces type safety through, ensuring that only messages of the defined type can be sent to an actor \cite{Abraham2023,akka-docs}. This differs from Elixir, where actor communication is dynamically typed and does not provide type guarantees.

Unlike Elixir, Scala permits mutable programming, which introduces the potential for shared mutable data to be passed between actors, a practice strongly discouraged in Akka’s documentation. Despite these guidelines, the use of mutable data within Akka is technically possible. If misused, this could reintroduce well-known concurrency issues in the JVM, such as race conditions and thread interference \cite{akka-docs}. This limitation stands in contrast to Elixir’s approach, where the \gls{VM} guarantees strict process isolation, effectively eliminating such risks \cite{Juric2024,Valkov2018}.

To achieve efficient performance, actors in Akka often share underlying threads, as individual threads are resource-intensive \cite{Moamen2027}. Akka actors mimic the lightweight processes of the \gls{BEAM} by managing multiple actors within a single thread. This approach significantly reduces memory consumption compared to the heavyweight \gls{JVM} threads. For instance, approximately 2.7 million Akka actors can fit within 1 GB of memory, a considerable contrast to the 4,096 threads that would occupy the same space \cite{Abraham2023}. That makes the minimum size of an acctor in Akka on an average 400 bytes.

Randtoul et al. \cite{Randtoul2022} examined the effectiveness of actor isolation in Erlang and Scala with Akka. Their findings revealed that server throughput is affected by the termination of server actors. Specifically, they observed that the throughput for both Erlang and Scala with Akka decreases only in proportion to the percentage of processes that fail. This leads to the conclusion that both Erlang and Scala/Akka offer robust process isolation.

\begin{comment}

\textit{\underline{Messager Dispatchers}}

Message dispatchers plays a important role in Akka’s architecture by managing the execution of actor tasks. A dispatcher serves as the mechanism that determines how messages are delivered to actors and how these actors are allocated to threads for execution. The default dispatcher is a thread pool executor based on the Fork/Join framework, enabling high concurrency with minimal overhead.

The flexibility of Akka dispatchers allows for fine-grained control over thread allocation, ensuring efficient utilization of system resources. For example, the pinned dispatcher assigns each actor its own dedicated thread, suitable for actors requiring uninterrupted execution. Conversely, the default dispatcher facilitates efficient thread sharing across a large number of actors. This configurability enables developers to tailor Akka’s performance characteristics to their application’s specific needs, such as minimizing latency or maximizing throughput.

Elixir’s message dispatching model, in contrast, is built into the \gls{BEAM} and abstracts much of the configuration from the developer. While this simplicity is advantageous, it lacks the level of customization offered by Akka. However, the \gls{BEAM}’s design provides guarantees of fairness and isolation, attributes that are less rigidly enforced in JVM-based systems, where developers must explicitly manage such concerns.

\textit{\underline{Garbage Collector}}

Another significant topic is garbage collection. As mentioned earlier, the \gls{BEAM} focuses on localized updates within individual processes, which allows for process-specific garbage collection. This ensures minimal disruption, as garbage collection can occur independently across processes. In contrast, the JVM employs heap-based garbage collection, which can trigger global stop-the-world pauses. Despite of  These pauses introduce the risk of application latency spikes or even node failures under high load. This fundamental difference highlights a critical limitation of JVM-based actor systems like Akka compared to the \gls{BEAM}, where garbage collection aligns more naturally with the principles of actor isolation.
\end{comment}

\subsection{Fault Tolerance Mechanism and Strategies}

Akka, built upon the Actor Model, inherits its fault-tolerance philosophy from Erlang’s design principles, like described on Elixir's section. This is the foundation of the fault tolerance aspects, at its core, the Actor Model facilitates fault tolerance through the supervisor pattern. By defining strategies for handling failures, such as restarting, stopping, or resuming child actors, supervisors ensure that errors are contained and localized, preventing system-wide failures \cite{akka-docs,Abraham2023,Juric2024}, like it was detailed before.

In addition to its foundational fault-tolerance mechanisms, Akka’s modular environment offers some modules that extend the toolkit’s capabilities, many of which directly contribute to improving fault tolerance.

\subsubsection{Akka Clustering}

Akka Cluster is a module that enables peer-to-peer communication among a group of nodes, allowing them to function as a unified distributed system \cite{Moradi2023,akka-docs}. Designed to enhance fault tolerance, it implements replication and redundancy strategies while achieving location transparency through the Artery protocol, enabling nodes to communicate without knowing the physical locations of others \cite{Abraham2023}.

The module provides an API for managing cluster operations, including managing nodes, designating a leader node, and obtaining cluster information. Although, Akka Cluster is autonomous, capable of redistributing workloads and managing actor states without manual intervention via API \cite{Abraham2023}. To ensure consistency and reliability, Akka Cluster employs a gossip protocol, a decentralized communication mechanism that facilitates the propagation of information across nodes \cite{Tanenbaum2023,akka-docs}. This protocol enables nodes to maintain a shared, consistent view of the cluster state \cite{Tanenbaum2023}.

For job processing, Akka Cluster employs a divide-and-conquer architecture through the use of master and worker actors. The master actor decomposes large tasks into smaller subtasks, distributing these among worker actors for parallel processing. Once processing is complete, the workers return their results to the master actor, which aggregates them to produce the final output. This design enhances performance and fault tolerance, as the master actor can reassign tasks from failed workers to other available nodes \cite{akka-docs}.

Leader election is a important aspect of a cluster management, and it is efficiently managed within Akka Cluster. In contrast to the Raft consensus, algorithm Akka Cluster adopts a simpler method by automatically assigning the leadership role to the node with the lowest address. This approach minimizes the overhead associated with the election process \cite{raft-diego,akka-docs}.

Furthermore, Akka Cluster supports advanced features such as cluster sharding, which distributes actors across the cluster while preserving their identity and state. This facilitates load balancing and enhances performance by ensuring that workloads are distributed evenly. The module also includes monitoring and health management capabilities, enabling to verify the performance and status of nodes and actors \cite{Abraham2023}.

\subsubsection{Akka Circuit Breaker}

Akka provides a dedicated module for implementing the Circuit Breaker pattern, a technique for improve system stability by isolating faults and preventing cascading failures. As presented earlier, the Circuit Breaker pattern temporarily suspends operations to a failing component, allowing it time to recover while safeguarding the overall system \cite{fowler-circuit-breakers}.

Akka’s Circuit Breaker module offers a straightforward integration, making it possible to configure the way the circuit it will activate, where it can be defined failure thresholds, timeouts, and recovery intervals. This module is effective in monitoring interactions between actors and external services, ensuring that errors are contained and managed without disrupting the broader system \cite{akka-docs}.

Compared to Elixir’s ecosystem, where circuit breaker functionality often relies on third-party libraries, Akka’s Circuit Breaker benefits from being a included part of its toolkit.

\subsubsection{Akka Persistence and Event Sourcing}

Akka offers support for distributed persistence, similar to the functionality provided by Mnesia in Elixir and Erlang \cite{akka-docs,elixir-docs-hexdocs}. It also features event sourcing, which contributes to fault tolerance through mechanisms such as message logging and check-pointing. Akka Persistence allows actors to recover their state after a failure. This is achieved by keeping an event log that records all changes to an actor’s state in the order they occur. Upon restart, typically initiated by a supervisor, the actor replays the logged events to reconstruct its previous state, allowing it to resume operations from the point prior to the failure \cite{akka-docs}.

To optimize the recovery process, Akka Persistence also supports snapshots, supporting also the check-pointing strategy. Instead of replaying all events from the beginning of the event log, the actor can restore its state from the most recent snapshot and then replay only the events that occurred after that snapshot \cite{Abraham2023,akka-docs}.

\subsection{Comparison with Elixir/BEAM and Real Applications}

The Akka toolkit marks a significant step forward in extending the \gls{JVM} to support modern concurrency models. As Valkov et al. \cite{Valkov2018} highlight, Akka improves Scala’s performance by reducing communication latency. However, since Akka functions as an abstraction layer on top of the \gls{JVM}, the same study by Valkov observed that Erlang exhibits lower communication latency compared to Scala with Akka. This difference is likely attributed to the \gls{BEAM}, which is considered a state of the art concurrency model \cite{erlang-concurrency-blog}. While the \gls{JVM} was originally developed to meet general-purpose programming needs with an emphasis on efficiency, it does not natively prioritize the actor model or process-level isolation in the way the \gls{BEAM} does.

However, Randtoul et al. \cite{Randtoul2022} studied how Erlang and Scala with Akka manage server actors failures using a supervisor control pattern. They tested two supervisor-to-actor ratios (1:1 and 1:64) to see how throughput is impacted by different failure types. Their findings showed that both systems had similar throughput reductions during burst and random failures, especially with the 1:1 ratio. However, surprisingly, Akka outperformed Erlang in uniform failure scenarios with the 1:1 ratio. Despite of not being a directly Elixir comparison, the underline it is the same making it a valid comparison and showing the potential of Akka.

\textbf{Garbage Collection.} A notable difference between Akka and the \gls{BEAM} lies in their approach to garbage collection. Akka relies on the \gls{JVM}’s garbage collection strategy, which can introduce latency during stop-the-world events \cite{akka-docs,Abraham2023}. These pauses can negatively affect the performance of highly concurrent systems, especially under heavy load. However, advancements in garbage collection technology, such as the Z Garbage Collector, have shown possibilities in reducing pause times significantly. As noted by Chaudhary et al. \cite{Chaudhary2024}, Z Garbage Collector represents a state of the art approach that is well-suited for applications requiring minimal pauses due to garbage collection. In contrast, the \gls{BEAM} employs a per-process garbage collection mechanism, which localizes memory management to individual lightweight processes \cite{Juric2024}. This architecture ensures that garbage collection in one process does not impact others, making the \gls{BEAM} particularly effective in low-latency and high-reliability scenarios.

\textbf{Scheduling Model.} Scheduling represents a fundamental difference between Akka and the \gls{BEAM}. The \gls{BEAM} employs a preemptive scheduling model designed to efficiently handle numerous small, short-lived tasks, such as high-frequency message handling in highly concurrent systems. This approach ensures equitable CPU time distribution and mitigates process starvation \cite{Juric2024,elixir-docs-hexdocs,erlang-concurrency-blog}. However, frequent context switching can introduce overhead for long-running processes, potentially reducing efficiency in such scenarios. Akka, on the other hand, relies on the \gls{JVM}’s cooperative scheduling model and enhances it with its Message Dispatcher, which supports configurable thread pools like Fork-Join, that leverages a work-stealing algorithm, and Fixed Thread Pools, optimizing resource usage. This mechanism enables Akka to efficiently manage long-lived and computationally intensive tasks \cite{akka-docs,Abraham2023}.

\textbf{Built-in Libraries and Support.} Both the Akka and Elixir/\gls{BEAM} ecosystems offer comprehensive libraries to address common design patterns for concurrency and fault tolerance. Elixir’s \gls{OTP} framework, like stated before, provides a robust suite of built-in patterns, such as supervisors, specifically tailored for managing concurrency and ensuring system reliability \cite{erlang-concurrency-blog,elixir-docs-hexdocs}. Akka, on the other hand, adopts a modular architecture with an easily pluggable library of features, including implementations for replication and circuit breakers. In the Elixir ecosystem, equivalent functionality is often achieved through third-party libraries maintained by the community. While these community-driven libraries are highly effective and widely used, their reliance on external maintenance and updates can present a potential drawback compared to Akka’s more integrated and officially supported approach.

\textbf{Real-World Applications.} Akka, just as Elixir, has demonstrated its capabilities in considerable large-scale applications, emphasizing its scalability, reliability, and performance. For instance, PayPal leverages Akka actors to manage over a billion financial transactions daily, ensuring high availability and robust fault tolerance \cite{Bagherzadeh2020}. Similarly, the Spark big data ecosystem depends on Akka for efficiently shuffling hundreds of terabytes of data across distributed nodes. Other prominent companies, including Twitter, LinkedIn, and Walmart use Akka to solve concurrency and distributed system challenges \cite{Bagherzadeh2020,akka-docs}.

\section{Go Programming Language Analysis}

The Go programming language was designed to facilitate rapid software development while ensuring high execution speed \cite{Kennedy2016, Cox-Buday2017}. It addresses the drawbacks of traditional low-level languages like C, which, while performant, can be complex for modern development. At the same time, Go offers a solution to the performance limitations of scripting languages such as Python, which prioritize ease of use but often fails in execution speed \cite{Kennedy2016}. As a statically typed, compiled language, Go enforces type safety \cite{go-docs}, setting it apart from dynamic and immutable languages like Elixir, as well as frameworks like Akka that also emphasize immutability with Scala.

While Go is not explicitly classified as a distributed or fault-tolerant programming language, it has gained considerable popularity in areas such as microservices, cloud applications, and high-concurrency systems. This popularity can be attributed to its simplicity, speed, and robust concurrency model \cite{Castro2019,Shuiskov2022}. In contrast to Elixir, which is designed with immutability and a let it crash fault-tolerance philosophy, Go does not inherently prioritize fault tolerance or the let it crash approach \cite{Cox-Buday2017}. Nevertheless, Go can be a good candidate for integration into distributed architectures when paired with complementary technologies and libraries. By take advantage of Go’s concurrency capabilities, it is possible to replicate the fault-tolerant strategies typical of Elixir-based systems, making it a valuable language to explore in this context.

\subsection{Concurrency and Distribution in Go}

Go adopts a concurrency model rooted in the \gls{CSP} paradigm, distinguishing itself from other approaches such as the Actor Model. While both paradigms prioritize concurrent communication, they are slightly different in their focus \cite{Cox-Buday2017}. In \gls{CSP}, channels are treated as first-class entities, emphasizing the communication mechanism itself, whereas the Actor Model considers processes to be first-class, focusing on the entities performing the computation, as described earlier. Additionally, the Actor Model enforces strict isolation between processes, with no shared memory, while CSP organizes concurrent processes to interact explicitly through channels rather than directly access to a single shared memory object \cite{Cox-Buday2017}.

Go is one of the first programming languages to integrate \gls{CSP} directly into its design, emphasizing data sharing through channels rather than passing references to shared memory among its lightweight threads, known as goroutines \cite{Cox-Buday2017}. This design choice minimizes potential synchronization complexities and aligns with Go’s guiding principle: “Do not communicate by sharing memory; instead, share memory by communicating” \cite{go-docs}. This philosophy contrasts with shared-memory concurrency models, where processes directly access and modify shared state. In Go, by design, only one goroutine can access a value at any given time, effectively eliminating the possibility of data races \cite{Kennedy2016,go-docs}. Nevertheless, Go also provides manual synchronization mechanisms, such as explicit mutexes, for situations where they are necessary \cite{Cox-Buday2017}.

In contrast to the Actor Model, where actors encapsulate state and communicate through asynchronous messages, Go’s \gls{CSP}-based model prioritizes structured communication patterns via channels. This distinction encourages developers to design systems by focusing on the flow of data and the relationships between processes, rather than the individual behavior of the computational units \cite{go-docs}.

Go's strategy utilizing \gls{CSP} is centered around goroutines and channels, which are described below. Additionally, it will be briefly discuss how Go's garbage collector operates, as well as the limitations of channels and goroutines in supporting distributed communication.

\subsubsection{Goroutines}

Due to the overhead associated with \gls{OS} threads, Go enhances efficiency by implementing a multiplexing logic that allows multiple processes to run on the same \gls{OS} thread \cite{Cox-Buday2017,Castro2019}, similar to the approaches used in Elixir and Akka. Go achieves this through goroutines, which are lightweight abstractions that enable concurrent and parallel execution. By utilizing goroutines, Go can efficiently manage numerous tasks without significant resource consumption \cite{go-docs}.

The \gls{OS} is responsible for scheduling threads to run on physical processors, whereas Go handles the scheduling of lightweight goroutines onto logical processors, which are subsequently bound to \gls{OS} threads \cite{Kennedy2016}. As shown in Figure \ref{fig:gorutine-threads-relation}, the example illustrate two \gls{OS} threads (M2 and M3), with goroutines identified by the prefix \textit{G}. The scheduling process involves allocating goroutines to logical processors via a local run queue. However, initially, goroutines are placed in the global scheduler run queue, and only afterward are they assigned to the local queues of logical processors \cite{Kennedy2016,Cox-Buday2017}. The same Figure \ref{fig:gorutine-threads-relation}, also illustrates how Go achieves parallelism. Goroutines can be distributed across multiple CPU cores if the hardware supports parallel execution \cite{Kennedy2016}.

\begin{figure}
    \centering
    \frame{\includegraphics[width=100mm]{ch-state/assets/goroutine-threads-relation.png}}
    \caption[Go’s scheduler logic of distributing goroutine by the logical processors]{Go’s scheduler logic of distributing goroutine by the logical processors. Adapted from \cite{Kennedy2016}.}
    \label{fig:gorutine-threads-relation}
\end{figure}

\subsubsection{Channels}

Building on the \gls{CSP} model, Go integrates channels as a core element of its concurrency paradigm. These data structures facilitate safe and efficient communication between goroutines, enhancing synchronization while addressing common challenges associated with shared memory access \cite{Kennedy2016}. By following the principle that only one goroutine should modify a piece of data at any given time, channels help ensure data integrity, reducing the risk of concurrent modification and giving predictable behavior in concurrent programs \cite{Cox-Buday2017}.

However, channels in Go do not inherently enforce data access protection features such as immutability and isolation \cite{Kennedy2016}, which are fundamental to the concurrency models found in languages like Elixir and Scala. These languages are specifically designed to facilitate effective concurrency management, like analyzed earlier. Nevertheless, it is possible to adopt a strategy of using immutable data within Go channels, where all information is a copy of the original data \cite{Cox-Buday2017}. This approach aligns more closely with the methodologies employed by Elixir and Scala, even though it is not the primary purpose of channels in Go.

\subsubsection{Garbage Collector}

In Go, the garbage collection strategy is based on a concurrent, non-generational mark-and-sweep algorithm \cite{go-docs}, which operates globally on the heap \cite{Zhao2023}. This approach differs significantly from the BEAM's garbage collector, which performs garbage collection on a per-process basis. The BEAM's process-level garbage collection minimizes the impact on overall system performance by isolating garbage collection events to individual processes \cite{Juric2024}.

Go's garbage collector, while global in nature, supports partial heap collection but still experiences "stop-the-world" pauses. Despite these challenges, it is designed to maintain pause times between 10 ms and 100 ms under heavy load, making it comparable to the G1 garbage collector in the JVM, which, as studied by Zhang et al. \cite{Zhang2021}, can experience pause times ranging from 0 to 300 ms. In contrast, ZGC achieves significantly lower pause times, typically between 0 and 0.1 ms, making it an attractive option for latency-sensitive applications, although it is not compatible with Go's environment \cite{Castro2019}.

Each garbage collection approach has its own advantages and trade-offs. Elixir’s garbage collection, rooted in the BEAM runtime, is particularly well-suited for distributed programming due to its strong emphasis on process isolation \cite{Armstrong2013}. In contrast, Go supports a partial heap-targeted garbage collector, which pairs effectively with its lightweight goroutines, enhancing memory management in concurrent applications.

\subsubsection{Distributed Communication}

A notable limitation of Go is its lack of native support for distributed communication \cite{Whitney2019, Cox-Buday2017}. While the combination of channels and goroutines serves as an excellent tool for managing concurrency and parallelism, it does not inherently extend to communication across physical machines \cite{Kennedy2016}. This limitation has prompted efforts to extend Go’s concurrency model to support distributed systems. For instance, Whitney et al. \cite{Whitney2019} proposed a novel protocol called Gluster, which provides a library to abstract cluster logic and facilitate distributed communication. However, Gluster has seen limited industrial adoption and is restricted to Linux environments, limiting its general applicability.

Nevertheless, Go it offers seamless integration with mature and optimized networking libraries \cite{Kennedy2016}. Packages such as \gls{TCP}, \gls{HTTP}, and \gls{gRPC} provide efficient mechanisms for enabling communication between distributed components \cite{Castro2019, go-docs}. These libraries significantly reduce the overhead associated with managing low-level networking concerns. Furthermore, channel-based networking libraries allow the management of distributed interactions effectively, leveraging goroutines and channels to handle the inherent asynchronous aspects of the network calls \cite{Castro2019}.

While Go’s native concurrency primitives do not align with the Actor Model, there are projects of the Actor Model available for the Go ecosystem. One mature example is Proto-Actor \cite{Whitney2019,proto-actor-docs}, a library that abstracts the complexities of distribution through its \gls{API}. Built on top of \gls{gRPC}, Proto-Actor provides a remote facilities and location transparency of the Actor Model within Go \cite{proto-actor-docs}.

Go’s rising popularity in the industry is closely tied to its adoption in microservices architectures and cloud-native applications \cite{Zhao2023,Shuiskov2022}. Microservices, by their nature, represent distributed systems and facilitate communication through both asynchronous and synchronous methods, often utilizing discovery services to map all nodes. Another approach involves the use of message queues, which can provide location transparency for processes \cite{Shuiskov2022}. However, these strategies may lead to over-engineering, in some cases, resulting in additional overhead compared to the native approach of Elixir.

\subsection{Fault Tolerance Mechanism and Strategies}

Go's approach to fault tolerance is not a central feature of the language, particularly in contrast to Elixir's "let it crash" philosophy. Instead, Go has a more explicit error-handling strategy that emphasizes direct management of errors. Also, to achieve fault-tolerance capabilities similar to those of Elixir and Akka, it is often necessary to rely on specific patterns and libraries.

\subsubsection{Error Philosophy}

Until now, the “let it crash” philosophy has been described, a core principle applied in both Elixir and Akka due to the inherent design of the Actor Model. This approach is based on the inevitability appearance of errors, allowing them to occur and relying on mechanisms like the supervisor pattern to detect and recover from them \cite{Armstrong2013}. However, the error-handling philosophy in Go is fundamentally different, representing almost the opposite paradigm. In Go, the strategy emphasizes handling every error explicitly \cite{Kennedy2016,go-docs}. Errors are treated as first-class citizens, returned as values, and must be actively managed by the program. Unlike languages such as Scala and even Elixir \cite{elixir-docs-hexdocs}, Go does not include mechanisms like try-catch for error handling. Instead, it enforces a more explicit style that requires developers to check for and respond to errors immediately after an operation \cite{Cox-Buday2017}.

This philosophy aligns with Go’s overall design principles of simplicity, clarity, and explicitness. It is supposed that requiring developers to handle errors explicitly, Go minimizes the risk of overlooking potential issues. While this approach can result in more verbose code, it aims to reduce the likelihood of unhandled exceptions and promote a clearer method of error management \cite{Kennedy2016, go-docs}.

Another important consideration in Go’s error handling philosophy is its impact on code readability and maintainability. The explicit nature of error handling in Go often leads to repetitive code blocks, resulting in more boilerplate compared to the code styles of Elixir and Akka \cite{Kennedy2016, go-docs}. However, this explicitness can facilitate tracing how errors are propagated and resolved within a program. In distributed systems, this approach can complement techniques such as logging and monitoring.

\subsubsection{Fault Tolerance Mechanisms and Strategies}

While Go was not primarily designed with built-in fault tolerance mechanisms, as it emphasizes efficiency and simplicity, it has become a fundamental component in distributed systems, such as Kubernetes \cite{Castro2019, Kennedy2016}. When combined with appropriate patterns, architectural approaches, and libraries, Go enables the development of fault tolerance capabilities within these systems.

A more suitable approach in Go combines the heartbeat pattern with panic/recover mechanisms \cite{Cox-Buday2017}. In this pattern, a goroutine functions as a supervisor, monitoring other goroutines through periodic status updates known as heartbeats or pulse. If a monitored goroutine fails to send a notification within the expected timeframe, the supervisor can initiate recovery procedures to restore the failed component's state \cite{Cox-Buday2017, go-docs}. This ensures that failures are detected and addressed promptly. Furthermore, the supervision mechanism can be enhanced by Go's panic/recover pattern, which enables the system to capture and handle critical errors. This approach is similar to the supervision trees in Elixir and Akka, but it operates on a more specific and internal level, rather than addressing distributed aspects if needed \cite{go-docs}.

A notable case study for this dissertation is Go's implementation of the Actor Model \cite{Whitney2019}. Roger Johansson, the creator of Akka.NET, with his team created an innovative approach to implementing the Actor Model in Go. This implementation demonstrates that the Actor Model can be effectively combined with \gls{CSP}, as these paradigms could be complementary rather than mutually exclusive \cite{proto-actor-docs}. Proto-Actor, positioned as a next-generation Actor Model framework, introduces the "Actor Standard Protocol," which establishes a language-agnostic protocol for communication across different programming languages \cite{proto-actor-docs}.

This implementation incorporates fault tolerance through the "let it crash" philosophy and location transparency within the Go programming language \cite{proto-actor-docs}. It employs gRPC and HTTP/2 \cite{proto-actor-docs}, representing a more modern approach compared to Akka’s Artery protocol and Erlang’s distributed protocol. While this design leverages Go’s efficiency, it is a library-based solution, similar to Scala with Akka, which introduces some overhead. However, there are two notable distinctions in execution: Akka runs on the JVM, while Go applications compile directly to machine code, potentially leading to different performance characteristics. Although direct comparisons with Scala with Akka and the JVM are not available, benchmarking tests for Proto-Actor show that it outperforms Akka.NET. Nevertheless, this performance advantage is unrelated to the JVM.

%Circuit breakers represent another pattern for fault tolerance in distributed applications \cite{fowler-circuit-breakers}. This pattern, being more generic and language-agnostic, prevents cascading failures by monitoring the health of dependent services or components and temporarily disabling failing components to prevent system-wide degradation \cite{fowler-circuit-breakers,Shuiskov2022}. The pattern integrates particularly well with Go's microservices architecture \cite{Shuiskov2022}.

In the context of microservices architecture, Go provides robust support through the mature Go-kit\footnote{Go-kit: \url{https://gokit.io/} (accessed 4 December 2024)} library \cite{go-kit-docs}. This library facilitates the development of microservices and distributed systems by implementing essential patterns such as circuit breakers, rate limiters, and distributed tracing capabilities \cite{go-kit-docs, Shuiskov2022}. Additionally, this framework can be enhanced with the failsafe-go\footnote{failsafe-go: \url{https://failsafe-go.dev/} (accessed 4 December 2024)} library, which introduces additional aspects of fault tolerance, such as retry policies. Furthermore, integrating HashiCorp's Raft\footnote{HashiCorp's Raft in Go: \url{https://github.com/hashicorp/raft/} (accessed 4 December 2024)} implementation can provide strong consistency and leader election capabilities.

Many of these solutions can be viewed as generic strategies that are more architectural than native, relying on third-party libraries. This is similar to the practices observed in Elixir, which frequently utilizes third-party solutions for replication, as well as in Akka for Scala. Nevertheless, the approaches outlined are effective and can capitalize on Go's popularity and efficiency.

\subsection{Challenges Compared With Akka and Elixir and Real Applications}

After examining the Go language, it is clear that it does not lend itself to fault tolerance mechanisms as naturally as Scala with Akka or Elixir. However, similar to how Akka enhances Scala, Proto-Actor leverages the combination of CSP with the Actor Model in Go \cite{proto-actor-docs}. Just as Elixir relies on third-party libraries to implement Raft consensus, Go also requires external libraries to achieve fault tolerance capabilities. Nevertheless, it easy to observe that Elixir's environment is robust and natively implements these features, providing a distinct advantage and a more convenient approach.

According to the Proto-Actor benchmarking performance results \cite{proto-actor-docs}, one test involved an initial actor spawning 10 new actors, each of which spawned another 10, continuing until a total of one million actors were created. Each actor returned its ordinal number, which was summed at the preceding level and sent back upstream to the root actor, resulting in a final sum in the range of 11 digits. In this test, Erlang outperformed the Actor Model implemented in Go, likely due to its optimized handling of short-lived processes.

In a different test, on the same source of Proto-Actor benchmarking performance results \cite{proto-actor-docs}, two actors, one on each of two nodes, were used to exchange one million messages back and forth. In this scenario, Go surpassed Erlang in throughput, a result attributed to Go’s use of message references, which likely reduced overhead.

A study conducted by Marchuk et al. \cite{Marchuk2023} revealed that Elixir outperformed Go in both requests per second and messages per second during a load test simulating a backend scenario. This test underscored Elixir's superior performance and efficiency.

In a similar vein, Valkov et al. \cite{Valkov2018} found that Go, likely due to its use of typed channels and the absence of a need for pattern matching, achieved higher throughput compared to Scala with Akka and Erlang. Notably, both Go and Erlang demonstrated the lowest message latency among the platforms evaluated. Furthermore, Go and Erlang exhibited more predictable scaling, with consistent increases in spawn time. In contrast, Scala with Akka experienced higher spawn times and less predictable scaling, particularly showing a significant performance spike when scaling from 10,000 to 20,000 processes.

\textbf{Maintainability and Readability of the Code.} One of the primary challenges when using Go for fault tolerance is the maintainability and readability of the code. While Go emphasizes simplicity and clarity, the absence of built-in fault tolerance mechanisms can lead to more complex code structures when implementing custom solutions \cite{go-docs}. In contrast, Elixir and Scala with Akka provide clear abstractions for fault tolerance, such as supervision trees and actor models, which inherently promote maintainability.

\textbf{Built-in Libraries and Support.} While Go has a growing ecosystem of libraries that facilitate fault tolerance, such as Go-kit and Proto-Actor, it lacks the extensive built-in support that Elixir and Akka offer. Elixir's OTP provides a rich set of libraries and tools specifically designed for building fault-tolerant systems, while Akka's actor model is deeply integrated into the framework.

\textbf{Real-World Applications.} Go is extensively used in cloud applications and high-performance systems \cite{Zhao2023}, particularly within Google, where it was originally developed. It plays a vital role in platforms such as Docker and Kubernetes, and companies like Dropbox have successfully transitioned from Python to Go to enhance efficiency \cite{go-docs}. Another notable example is Cockroach Labs, which has praised Go's garbage collection and performance as well-suited to their requirements \cite{go-docs}. However, challenges do exist. For instance, Discord initially implemented Go but later migrated to Rust due to issues with Go's garbage collection, which resulted in significant latency spikes. This led to the conclusion that the garbage collector was a contributing factor to performance degradation \cite{discord-blog-rust-go}.

\section{Benchmarking Analyses}

According to Almeida et al. \cite{Almeida2013}, the primary objectives of benchmarking are to \textit{“provide a practical way to characterize and compare systems or components according to specific characteristics (e.g., performance, dependability)}”. Benchmarking delivers insights within a specific domain by quantifying key metrics, enabling practical comparisons. For results to be valid and meaningful, it is critical to conduct precise, repeatable experiments. Benchmarking serves as an experimental approach that derives value from measurable outcomes, which can be deterministic, yielding consistent results under identical conditions, or statistically analyzed \cite{Almeida2013, Blessing2019}. Deterministic benchmarks are especially valuable as they ensure reproducibility when the same assumptions are applied.

Non-deterministic approaches are typically associated with chaos engineering, which focuses on testing system resilience by intentionally introducing random faults \cite{Randtoul2022}. However, the insights gained from benchmarking in this context are relative and applicable only to the specific conditions under which the tests were conducted, due to the inherent randomness of the process. Consequently, these tests often lack reproducibility and may not offer comprehensive coverage across all system sizes \cite{Almeida2013}.

On a overview, benchmarking is generally divided into two categories \cite{Imam2014,Blessing2019,Valkov2018,Almeida2013}:
\begin{itemize}
    \item \textbf{Macro Benchmarking:} This approach assesses the overall performance of an application or system. It evaluates the application as a whole, which can make it difficult to isolate and analyze specific components or performance aspects. Macro benchmarking is particularly useful when it is important to observe the interactions among components in their entirety.
    \item \textbf{Micro Benchmarking:} This method focuses on individual components, functions, or metrics, allowing for detailed and targeted analyses. Micro benchmarking is especially beneficial for studies that require an in-depth examination of specific aspects of the application, enabling developers to identify performance bottlenecks and optimize accordingly.
\end{itemize}

The well-known Computer Language Benchmarks Game\footnote{Computer Language Benchmarks Game: \url{https://benchmarksgame-team.pages.debian.net/benchmarksgame/} (accessed 4 December 2024)} supports various algorithmic benchmarking tests, evaluating runtime, memory usage, and related performance metrics \cite{Blessing2019}. However, this benchmarkings does not support newer languages like Elixir, Scala, and Scala with Akka, nor does it address resilience-focused benchmarks. This limitation highlights the need for dedicated tools and frameworks tailored to resilience benchmarking in modern programming environments.

Building on this introduction, the following section will present a literature review focused on benchmarking in this area, specifically addressing actor-based benchmarking as well as server and distributed benchmarking. This overview will highlight the current state of the literature and the advancements in the field, detailing key points relevant to the objectives of this dissertation, which centers on distributed and fault-tolerant benchmarking.

\begin{comment}    
\subsection{Literature Review of Benchmark}

Imam et al. \cite{Imam2014} developed an actor benchmarking framework called Savina, designed for actor-based languages running on the \gls{JVM}. Savina includes 30 built-in programs that analyze various actor-related problems, such as the ping-pong benchmark, where two actors exchange messages back and forth; the thread-ring benchmark, where a token circulates among N connected actors; and the fork-join strategy, which creates millions of actors sequentially, sends each a single message to process with minimal computation, and then terminates the actors. This benchmarking framework evaluates aspects such as messaging throughput, message-passing overhead, and resource allocation efficiency on \gls{IPC}, among other metrics. Despite its strengths, Savina’s focus on \gls{JVM} languages limits its applicability to languages like Elixir and Go, and it lacks robust support for resilience testing. Nevertheless, its strategies and metrics remain valuable for actor-system analysis.

Blessing et al. \cite{Blessing2019} proposed an improved approach to testing reliability in Actor Models, drawing inspiration from Savina, which is considered the current de facto benchmark. The study aimed to extend Savina’s capabilities to support the Pony language, given that Savina was originally limited to the \gls{JVM}. However, the authors argued for a more versatile approach: creating a generic application tailored to a common real-world use case, such as a chat application resembling those used in platforms like Facebook or WhatsApp. This approach emphasizes developing expertise and optimizing a single application rather than focusing on diverse algorithms. The proposed application design consists of three main components: a load balancer and three types of actors: clients, directories, and chats. A client represents a server-side proxy for a hypothetical client device. A directory serves as a load-balancing mechanism that maps client IDs to their corresponding actor handles. A chat actor models a conversation, maintaining the history of the chat and a list of participating clients, while forwarding incoming messages to all involved actors. The design allows for extensive customization to simulate real-world scenarios. For example, the application can be tuned to increase the computational workload on clients, replicate bottlenecks by adjusting the number of directories, or vary the message size to observe performance impacts. This flexibility ensures the application effectively simulates realistic conditions for benchmarking and reliability testing.

Randtoul et al. \cite{Randtoul2022} are considered state of the art in testing the reliability of actor-based server languages, introducing the concept of Supervised Communicating Processes. The authors argue that chaos engineering lacks value for this benchmarking as it does not produce deterministic results. Their study focuses on Erlang and Akka, particularly the supervisor pattern and reliability aspects, using four fault load patterns: burst, random, uniform, and progressive. The uniform pattern evenly distributes failures across components, the burst pattern rapidly terminates a set of actors/processes in succession, the random pattern combines burst and uniform patterns for a realistic scenario, and the progressive pattern kills actors/processes at 5-second intervals, enabling diverse fault-tolerance evaluations.

Valkov et al. \cite{Valkov2018} conducted a study comparing Erlang, Go, and Scala with Akka, focusing on server performance. The study provided performance insights using matrix multiplication, stated by the authors as a complex algorithm suitable for parallelization. Key metrics evaluated included process communication latency, process creation time, the maximum number of processes supported, and concurrent process throughput. However, the study did not address resilience or distributed aspects, limiting its scope to performance.
\end{comment}


\subsection{Fault-Tolerant and Distributed Benchmarking}

Benchmarking fault tolerance in distributed systems presents specific challenges, requiring evaluative strategies that extend beyond conventional performance testing. Key considerations include not only throughput and latency under nominal conditions, or how the computational occurs under an algorithm execution, but also the ability to keep executing, to detect and recover from faults, including node failures, communication interruptions, and state inconsistencies \cite{Randtoul2022, Blessing2019, Almeida2013}. This complexity necessitates diverse strategies and comprehensive metrics that evaluate both individual components and their interactions within the system.

The objective is to develop benchmarks that accurately simulate real-world errors. These benchmarks should closely reflect actual software behavior, taking into account factors such as overload conditions and software faults. In fault-tolerance benchmarks, it is crucial to incorporate components that introduce faults in order to achieve dynamic accuracy. This can be accomplished through random fault injection methods, such as Chaos Monkey, developed by Netflix, which randomly destabilizes the system, or through deterministic fault injections, where specific errors are deliberately introduced into the system and it is known what happened in order to corelate the metrics with the faults.

Distributed benchmarks present several challenges, particularly in maintaining effective communication between components. These challenges can lead to increased latency and may involve physical limitations, such as managing multiple machines, dealing with diverse hardware configurations, and relying on network connectivity. One effective strategy to address these challenges is to simulate a distributed environment on a single machine by employing multiple virtual machines or containers. This approach allows for the testing of distributed systems without the complexities of managing separate physical hardware. In this setup, the primary variable that can be manipulated is latency, enabling a more controlled and efficient benchmarking process.

Benchmarking fault tolerance involves strategies ranging from micro-benchmarks focused on isolated system behaviors to macro-benchmarks simulating real-world applications. Each approach has unique strengths and trade-offs, suggesting that a hybrid methodology might yield the most comprehensive insights.
\todo{melhorar}

\subsubsection{Strategies}

The Computer Language Benchmarks Game, as previously introduced, provides a foundational collection of micro-benchmarks designed to compare the performance of programming languages. Although it does not include distributed systems and lacks support for some newer languages, it has a set of algorithms that have served as the basis for other benchmarks, such as the work by \textcite{Cardoso2013}. This particular benchmark focuses on the agent and actor model, leveraging three algorithms from the collection: Fibonacci numbers, token-ring\footnote{The token-ring algorithm simulates a network of nodes passing tokens in a circular manner, which is useful for evaluating message-passing and synchronization in concurrent systems \cite{Cardoso2013}.}, and chameneos-redux\footnote{Chameneos-redux is a concurrency benchmark that models a group of agents (chameneos) interacting with each other based on color, showcasing the complexities of state management and communication in concurrent programming \cite{Cardoso2013}.}. These algorithms, each tailored to distinct computational tasks, offer a valuable resource for designing performance tests in a variety of contexts \cite{Cardoso2013,Randtoul2022}. They can be used in conjunction with resilience benchmarks to simulate processing, for example.

For instance, Savina, developed by \textcite{Imam2014}, has emerged as the de facto benchmark for evaluating actor model performance. It utilizes micro-benchmarks alongside concurrency and parallelism techniques to assess the behavior of actor-oriented programs in compute-intensive applications. While Savina provides valuable performance insights, its scope is restricted to JVM-based languages, such as Akka with Java, thereby excluding languages like Elixir, Go, and Scala with Akka. Additionally, its focus is limited to single-node environments, offering no support for evaluating distributed systems.

Savina employs 28 benchmarking strategies, categorized into three groups: 7 for micro-benchmarking, 8 for concurrency, and 13 for parallelism. These benchmarks evaluate critical aspects such as communication efficiency, node creation and termination, mailbox contention, \gls{IPC} resource allocation, among others \cite{Imam2014,Blessing2019}. However, Savina’s focus is confined to actor-based systems and localized performance, excluding non-actor-based and distributed communication scenarios.

\textcite{Blessing2019} highlighted significant limitations in the micro-benchmarking Savina, particularly their narrow focus on isolated performance metrics. To address these issues, they proposed an application-oriented benchmarking approach that simulates real-world scenarios, such as a chat application like Facebook or WhatsApp. This approach shifts away from isolated micro-benchmarks, such as evaluating latency in message-passing programs, to consider broader application-level metrics.

Their proposal centers on creating a comprehensive application that encompasses multiple scenarios. This approach aims to make benchmarks more relatable to real-world applications, encouraging developers to optimize the all system performance rather than focusing on discrete, independent cases \cite{Blessing2019}. To enhance flexibility, they introduced tunable options, such as varying the number of load balancers, if applicable, to simulate bottlenecks or adjusting message sizes to test system behavior under different conditions, for example.

Despite its innovative approach, the implementation by \textcite{Blessing2019} had notable shortcomings. It did not support stateful clients, distributed environments spanning virtual machines, or resilience testing. Additionally, the proposed implementation was limited to Erlang, Pony, and the C++ Actor Framework (CAF). These limitations highlight opportunities to design advanced application-based benchmarks that incorporate fault-tolerance techniques and cater to broader, more complex distributed systems.

\textcite{Randtoul2022} present a study focused on evaluating the resilience of actor-based systems under fault scenarios through fault injection techniques. The authors did not used chaos engineering due to its inherent unpredictability, opting instead for a deterministic approach. This choice ensures reproducibility and controlled experimentation. Being deterministic, also facilitates a clear relation between fault inputs and the resulting metrics.

The benchmark developed in the study operates within a single physical machine, deploying multiple nodes without relying on separate physical machines or cloud-based resources \cite{Randtoul2022}. It employs the supervisor pattern, a mechanism designed to recover from errors affecting supervised actors. The system allows for customization of the supervisor-to-supervisee ratio, with configurations ranging from 1:1 to 1:1024. Fault injection tests are designed to simulate errors that closely mirror real-world scenarios, using the following fault patterns \cite{Randtoul2022}:

\begin{itemize}
    \item \textbf{Uniform Failure Pattern:} Distributes failures evenly, by a spontaneous injection, simulating periodic failures typical of web servers handling distributed requests.
    \item \textbf{Burst Failure Pattern:} Simulates sequential or simultaneous actor failures, mimicking hardware or network errors that propagate, potentially causing widespread system disruptions.
    \item \textbf{Random Failure Pattern:} Combines characteristics of burst and isolated failures, representing a realistic mix of spontaneous single failures and clusters of failing processes.
    \item \textbf{Progressive Permanent Failures:} Gradually terminates actors or processes at fixed intervals, such as every five seconds, for example, to simulate irrecoverable scenarios. This contrasts with the, before detailed, recovery patterns by emphasizing the inability to restore normal function.
\end{itemize}

The benchmark was implemented using Erlang and Scala with Akka \cite{Randtoul2022}. The authors noted a limitation of the benchmark, that is the inability to utilize stateful actors, which presents certain challenges. Consequently, all tests were conducted using stateless actors.

After reviewing the most recent and relevant benchmark studies suitable, for this case, it is concluded that there are gaps in the current benchmarks available. However, these gaps present an opportunity to propose a benchmarking approach in this dissertation. This approach could employ a hybrid methodology, integrating various aspects discussed in the reviewed studies. For example, it could incorporate the fault injection strategies detailed in the work of \cite{Randtoul2022}, while adopting the generic application framework proposed by \cite{Blessing2019}, which involves implementing a chat application. To address distributed communication, all nodes could be deployed on a single physical machine across different \glspl{VM}, as similar of the work described on \cite{Randtoul2022}. This setup minimizes the complexities associated with infrastructure management and network latency, as the nodes are distributed across virtual machines on the same host.

\subsubsection{Metrics}

Metrics are a fundamental aspect of the benchmarking process, providing a quantitative basis for evaluating system characteristics. They represent measurable outcomes of system execution and are essential for drawing meaningful conclusions \cite{Almeida2013}. The choice of metrics is critical, as it defines the evaluation scope and ensures the relevance of the results \cite{Almeida2013,Kleppmann2017}.

In the observed context, metrics are generally categorized into two main types: performance-focused metrics and fault tolerance metrics \cite{Valkov2018,Randtoul2022,Almeida2013}. Performance metrics assess system efficiency and responsiveness, either independently or in conjunction with fault tolerance, to evaluate how the system performs under normal and faulty conditions \cite{Valkov2018}. In contrast, fault tolerance metrics specifically examine a system's ability to manage and recover from failures, including metrics such as recovery time and fault handling capacity. Combining these perspectives provides a comprehensive evaluation, offering deeper insights into system performance and reliability \cite{Randtoul2022}.

For this study, metrics such as those employed by Valkov et al. \cite{Valkov2018}, process creation time and latency among concurrent, are useful to assess server performance. Additionally, performance metrics from the Savina benchmarking suite \cite{Imam2014}, which focuses on message passing and actor-based performance aspects, are considered a valuable. Fault tolerance metrics add further depth by measuring specific attributes related to failure management \cite{Randtoul2022}, where it has information about how system can recover.

For this type of benchmark it is valuabel metrics such as \gls{MTTR}, the , where it verifies which are the times that it takes to detect and to recover from the errors, where it is suitable for . 

Static metrics are another critical focus area, providing insights into the structural properties of the software. These metrics are influenced by language-specific implementations and API differences. For instance, comparing the Go programming language without an Actor Model framework to other implementations highlights trade-offs between language design and system performance. Static metrics facilitate a comparative analysis of maintainability, complexity, and system behavior across programming languages and frameworks, offering valuable data for optimizing software design.

\section{Conclusions}

After the research about the topics of study, it is now possibility to answear to the research questions and also state what are the goals to the upcomming work of this dissertation with the future work.

\subsection{Research Questions}

\subsection{Future Work}