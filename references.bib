@inproceedings{Valkov2018,
   abstract = {Servers are a key element of current IT infrastructures, and must often deal with large numbers of concurrent requests. The programming language used to construct the server has an important role in engineering efficient server software, and must support massive concurrency on multicore machines with low communication and synchronisation overheads. This paper investigates 12 highly concurrent programming languages suitable for engineering servers, and analyses three representative languages in detail: Erlang, Go, and Scala with Akka. We have designed three server benchmarks that analyse key performance characteristics of the languages. The benchmark results suggest that where minimising message latency is crucial, Go and Erlang are best; that Scala with Akka is capable of supporting the largest number of dormant processes; that for servers that frequently spawn processes Erlang and Go minimise creation time; and that for constantly communicating processes Go provides the best throughput.},
   author = {Ivan Valkov and Natalia Chechina and Phil Trinder},
   doi = {10.1145/3167132.3167144},
   isbn = {9781450351911},
   booktitle = {Proceedings of the ACM Symposium on Applied Computing},
   keywords = {Akka,Erlang,Go,Programming languages,Scala,Server applications},
   month = {4},
   pages = {218-225},
   publisher = {Association for Computing Machinery},
   title = {Comparing languages for engineering server software: Erlang, go, and scala with akka},
   year = {2018},
}
@misc{Sharma2016,
   abstract = {In this paper, we give a survey on various fault tolerance techniques and related issues in distributed systems. More specially speaking, we talk about two most important issues; multiple fault handling capability and performance. This survey provides the related research results and also explored the future directions about fault tolerance techniques, and it is a good reference for researcher.},
   author = {Sanjeev Sharma and Rajiv Gandhi Proudhyogiki and Sanjay Bansal},
   issue = {1},
   journal = {IJIDCS) International Journal on Internet and Distributed Computing Systems},
   keywords = {Distributed-Computing,Fault-Tolerance,Multiple Faults,Replication},
   pages = {33},
   title = {A Detailed Review of Fault-Tolerance Techniques in Distributed System},
   volume = {1},
   url = {https://www.researchgate.net/publication/228619369},
   year = {2016},
}
@inproceedings{Randtoul2022,
   author = {Aidan Randtoul and Phil Trinder},
   doi = {10.1145/3546186.3549928},
   isbn = {9781450394352},
   booktitle = {Erlang 2022 - Proceedings of the 21st ACM SIGPLAN International Workshop on Erlang},
   keywords = {Benchmark,Distributed System,Erlang,Fault Tolerance,Reliability,Server},
   month = {9},
   pages = {21-32},
   publisher = {Association for Computing Machinery, Inc},
   title = {A reliability benchmark for actor-based server languages},
   year = {2022},
}
@article{Ferreira1944,
   abstract = {Programming language advances have played an important role in various areas of distributed systems research, including consistency, communication, and fault tolerance, enabling automated reasoning and performance optimization. However, over the last few years, researchers focusing on this area have been scattered across different communities such as language design and implementation , (distributed) databases, Big Data processing and IoT/edge computing-resulting in limited interaction. The goal of this seminar is to build a community of researchers interested in programming language techniques for distributed systems and distributed data management, share current research results and set up a common research agenda. This report documents the program and the outcomes of Dagstuhl Seminar 19442 "Programming Languages for Distributed Systems and Distributed Data Management." License Creative Commons BY 3.0 Unported license © Carla Ferreira, Philipp Haller, and Guido Salvaneschi, Developing distributed systems is a well-known, decades-old problem in computer science. Despite significant research effort dedicated to this area, programming distributed systems remains challenging. The issues of consistency, concurrency, fault tolerance, as well as (asynchronous) remote communication among heterogeneous platforms naturally show up in this class of systems, creating a demand for proper language abstractions that enable developers to tackle such challenges. Over the last years, language abstractions have been a key for achieving the properties above in many industrially successful distributed systems. For example, MapReduce takes advantage of purity to parallelize task processing; complex event processing adopts declarative Except where otherwise noted, content of this report is licensed under a Creative Commons BY 3.0 Unported license},
   author = {Carla Ferreira and Philipp Haller and Guido Salvaneschi and Dagstuhl Reports},
   doi = {10.4230/DagRep.9.10.117},
   journal = {Dagstuhl Reports},
   keywords = {2012 ACM Subject Classification Software and its engineering → General programming lan-guages,Computer systems organization → Distributed architectures,Computer systems organization → Embedded and cyber-physical systems Keywords and phrases Programming Languages,Data Management,Distributed Systems,Information systems → Data management systems},
   pages = {117-133},
   title = {Programming Languages for Distributed Systems and Distributed Data Management},
   volume = {9},
   url = {http://www.dagstuhl.de/19442},
   year = {1944},
}
@book{Armstrong2013,
   abstract = {This second edition of Joe's seminal Programming Erlang is a welcome update, covering not only the core language and framework fundamentals but also key community projects such as rebar and cowboy. Even experienced Erlang programmers will find helpful tips and new insights throughout the book, and beginners to the language will appreciate the clear and methodical way Joe introduces and explains key language concepts.},
   author = {Joe Armstrong},
   isbn = {978-1-937785-53-6},
   title = {Early Praise for Programming Erlang, Second Edition},
   year = {2013},
}
@book{Tanenbaum2023,
   author = {S. Andrew Tanenbaum and M. Maarten Van Steen},
   edition = {4},
   isbn = {978-90-815406-3-6},
   publisher = {Maarten Van Steen},
   title = {Distributed systems},
   year = {2023},
}
@misc{Haider2011,
   abstract = {Distributed systems are responsible for providing the main execution platform for High Performance Computing (HPC). As distributed systems can be homogeneous (cluster) as well as heterogeneous (grid and cloud etc), they are prone to different kinds of problems. The issues in distributed systems can be Security, Quality of Service, Resource Selection and Fault Tolerance etc. Fault tolerance is responsible for handling the reliability and availability of distributed systems. It is not feasible to ignore job failures in distributed environments where long and persistent commitments of resources are required. In this paper we have presented a comprehensive classification of errors, failures and faults that can be encountered in a Distributed environment. Furthermore, we have examined different fault identification and tolerance techniques available in different Clustered and Grid Computing environments. Fault detection and tolerance techniques used in homogeneous and heterogeneous environments are different from each other and are not interoperable. We have proposed in this paper that a standard fault tolerant framework should be there capable of handling all the identified errors, failures and faults.},
   author = {Sajjad Haider and Naveed Riaz Ansari and Muhammad Akbar and Mohammad Raza Perwez and Khawaja Moyeezullah Ghori},
   keywords = {Cluster, Grid,Distributed Systems,Fault Tolerance},
   publisher = {IACSIT Press},
   title = {Fault Tolerance in Distributed Paradigms},
   volume = {5},
   year = {2011},
}
@misc{Haridi1998,
   abstract = {Much progress has been made in distributed computing in the areas of distribution structure, open computing, fault tolerance, and security. Yet, writing distributed applications remains difficult because the programmer has to manage models of these areas explicitly. A major challenge is to integrate the four models into a coherent development platform. Such a platform shoUld make it possible to cleanly separate an application's functionality from the other four concerns. Concurrent constraint programming, an evolution of concurrent logic programming, has both the expressiveness and the formal foundation needed to attempt this integration. As a first step, we have designed and built a platform that separates an application's functionality from its distribution structure. We have prototyped several collaborative tools with this platform, including a shared graphic editor whose design is presented in detail. The platform efficiently implements Distributed Oz, which extends the Oz language with constructs to express the distribution structure and with basic primitives for open computing, failure detection and handling, and resource control. Oz appears to the programmer as a concurrent object-oriented language with dataflow synchronization. Oz is based on a higher-order, state-aware, concurrent constraint computation model.},
   author = {Self Haridi and Peter Van Roy and Per Brand and Christian Schulte},
   journal = {New Generation Computing},
   pages = {223-261},
   publisher = {Springer-Verlag},
   title = {Programming Languages for Distributed Applications},
   volume = {16},
   year = {1998},
}
@article{Trinder2017,
   abstract = {Distributed actor languages are an effective means of constructing scalable reliable systems, and the Erlang programming language has a well-established and influential model. While the Erlang model conceptually provides reliable scalability, it has some inherent scalability limits and these force developers to depart from the model at scale. This article establishes the scalability limits of Erlang systems and reports the work of the EU RELEASE project to improve the scalability and understandability of the Erlang reliable distributed actor model. We systematically study the scalability limits of Erlang and then address the issues at the virtual machine, language, and tool levels. More specifically: (1) We have evolved the Erlang virtual machine so that it can work effectively in large-scale single-host multicore and NUMA architectures. We have made important changes and architectural improvements to the widely used Erlang/OTP release. (2) We have designed and implemented Scalable Distributed (SD) Erlang libraries to address language-level scalability issues and provided and validated a set of semantics for the new language constructs. (3) To make large Erlang systems easier to deploy, monitor, and debug, we have developed and made open source releases of five complementary tools, some specific to SD Erlang. Throughout the article we use two case studies to investigate the capabilities of our new technologies and tools: a distributed hash table based Orbit calculation and Ant Colony Optimisation (ACO). Chaos Monkey experiments show that two versions of ACO survive random process failure and hence that SD Erlang preserves the Erlang reliability model. While we report measurements on a range of NUMA and cluster architectures, the key scalability experiments are conducted on the Athos cluster with 256 hosts (6,144 cores). Even for programs with no global recovery data to maintain, SD Erlang partitions the network to reduce network traffic and hence improves performance of the Orbit and ACO benchmarks above 80 hosts. ACO measurements show that maintaining global recovery data dramatically limits scalability; however, scalability is recovered by partitioning the recovery data. We exceed the established scalability limits of distributed Erlang, and do not reach the limits of SD Erlang for these benchmarks at this scale (256 hosts, 6,144 cores).},
   author = {Phil Trinder and Natalia Chechina and Nikolaos Papaspyrou and Konstantinos Sagonas and Simon Thompson and Stephen Adams and Stavros Aronis and Robert Baker and Eva Bihari and Olivier Boudeville and Francesco Cesarini and Maurizio Di Stefano and Sverker Eriksson and Viktória Fördos and Amir Ghaffari and Aggelos Giantsios and Rickard Green and Csaba Hoch and David Klaftenegger and Huiqing Li and Kenneth Lundin and Kenneth Mackenzie and Katerina Roukounaki and Yiannis Tsiouris and Kjell Winblad},
   doi = {10.1145/3107937},
   issn = {15584593},
   issue = {4},
   journal = {ACM Transactions on Programming Languages and Systems},
   keywords = {Erlang,Reliability,Scalability},
   month = {8},
   publisher = {Association for Computing Machinery},
   title = {Scaling reliably: Improving the scalability of the Erlang distributed actor platform},
   volume = {39},
   year = {2017},
}
@misc{Haridi1998,
   abstract = {Much progress has been made in distributed computing in the areas of distribution structure, open computing, fault tolerance, and security. Yet, writing distributed applications remains difficult because the programmer has to manage models of these areas explicitly. A major challenge is to integrate the four models into a coherent development platform. Such a platform shoUld make it possible to cleanly separate an application's functionality from the other four concerns. Concurrent constraint programming, an evolution of concurrent logic programming, has both the expressiveness and the formal foundation needed to attempt this integration. As a first step, we have designed and built a platform that separates an application's functionality from its distribution structure. We have prototyped several collaborative tools with this platform, including a shared graphic editor whose design is presented in detail. The platform efficiently implements Distributed Oz, which extends the Oz language with constructs to express the distribution structure and with basic primitives for open computing, failure detection and handling, and resource control. Oz appears to the programmer as a concurrent object-oriented language with dataflow synchronization. Oz is based on a higher-order, state-aware, concurrent constraint computation model.},
   author = {Self Haridi and Peter Van Roy and Per Brand and Christian Schulte},
   journal = {New Generation Computing},
   pages = {223-261},
   publisher = {Springer-Verlag},
   title = {Programming Languages for Distributed Applications},
   volume = {16},
   year = {1998},
}
@book{Nystrom2009,
   author = {Jan Henry Nystrom},
   isbn = {978-91-554-7532-1},
   keywords = {erlang,fault tolerance,formal methods,symbolic evaluation},
   title = {Fault Tolerance in Erlang},
   year = {2009},
}
@inproceedings{Earle2005,
   abstract = {In this paper we target the verification of fault tolerant aspects of distributed applications written in Erlang. Erlang is unusual in several respects. First, it is one of a few functional languages that is used in industry. Secondly the programming language contains support for concurrency and distribution as well as including constructs for handling fault-tolerance. Erlang programmers, of course, mostly work with ready-made language components. Our approach to verification of fault tolerance is to verify systems built using two central components of most Erlang software, a generic server component with fault tolerance handling, and a supervisor component that restarts failed processes. To verify Erlang programs built using these components we automatically translate them into processes of the μCRL process algebra, generate their state spaces, and use a model checker to determine whether they satisfy correctness properties specified in the μ-calculus. The key observation of this paper is that, due to the usage of these higher-level design patterns (supervisors and generic servers) that structure process communication and fault recovery, the state space generated from a Erlang program, even with failures occurring, is relatively small, and can be generated automatically. Moreover the method is independent from the actual Erlang program studied, and is thus reusable. We demonstrate the approach in a case study where a server, built using the generic server component, implements a locking service for a number of client processes, and show that the server tolerates client failures. Copyright © 2005 ACM.},
   author = {Clara Benac Earle and Lars Åke Fredlund and John Derrick},
   doi = {10.1145/1088361.1088367},
   isbn = {1595930663},
   booktitle = {Erlang'05 - Proceedings of the ACM SIGPLAN 2005 Erlang Workshop},
   keywords = {Code Verification,Concurrency,Fault-Tolerance},
   pages = {26-34},
   title = {Verifying fault-tolerant Erlang programs},
   year = {2005},
}
@misc{Adnan2011,
   abstract = {A fault tolerance system is required for developing highly reliable computing systems that can function under adverse conditions, which is indispensable in safety critical applications. Fault tolerance is a major research issue in computing system designs because of the difficulty in producing error-free computing systems. This paper presents the recent development of software fault tolerance techniques and compares the performance of different software fault tolerant techniques and provides future research directions.},
   author = {Nasim Adnan and Md Nasim Adnan and Akbar Kabir and Lutful Karim and Nargis Khan},
   journal = {ULAB JOURNAL OF SCIENCE AND ENGINEERING},
   keywords = {()},
   note = {fala sobre os tópicos de fault tolerance.<br/>},
   pages = {2079-4398},
   title = {Performance Comparison of Different Software Fault Tolerance Methods},
   volume = {2},
   url = {https://www.researchgate.net/publication/301294807},
   year = {2011},
}
@misc{Reis2005,
   abstract = {Traditional fault tolerance techniques typically utilize resources ineffectively because they cannot adapt to the changing reliability and performance demands of a system. This paper proposes software-controlled fault tolerance, a concept allowing designers and users to tailor their performance and reliability for each situation. Several software-controllable fault detection techniques are then presented: SWIFT, a software-only technique, and CRAFT, a suite of hybrid hardware/ software techniques. Finally, the paper introduces PROFiT, a technique which adjusts the level of protection and performance at fine granularities through software control. When coupled with software-controllable techniques like SWIFT and CRAFT, PROFiT offers attractive and novel reliability options.},
   author = {George A Reis and Jonathan Chang and Neil Vachharajani and Ram Rangan and David I August and Shubhendu S Mukherjee},
   keywords = {C42 [Performance of Systems]: Fault tolerance General Terms: Reliability Additional Key Words and Phrases: software-controlled fault tolerance,fault detection,reliability},
   title = {Software-Controlled Fault Tolerance},
   year = {2005},
}
@misc{Hasan2018,
   abstract = {Fault tolerance is among the most imperative issues in cloud to deliver reliable services. It is difficult to implement due to dynamic service infrastructure, complex configurations and various interdependencies existing in cloud. Extensive research efforts are consistently being made to implement the fault tolerance in cloud. Implementation of a fault tolerance policy in cloud not only needs specific knowledge of its application domain, but a comprehensive analysis of the background and various prevalent techniques also. Some recent surveys try to assimilate the various fault tolerance architectures and approaches proposed for cloud environment but seem to be limited on some accounts. This paper gives a systematic and comprehensive elucidation of different fault types, their causes and various fault tolerance approaches used in cloud. The paper presents a broad survey of various fault tolerance frameworks in the context of their basic approaches, fault applicability, and other key features. A comparative analysis of the surveyed frameworks is also included in the paper. For the first time, on the basis of an analysis of various fault tolerance frameworks cited in the present paper as well as included in the recently published prime surveys, a quantified view on their applicability is presented. It is observed that primarily the checkpoint-restart and replication oriented fault tolerance techniques are used to target the crash faults in cloud.},
   author = {Moin Hasan and Major Singh Goraya},
   doi = {10.1016/j.compind.2018.03.027},
   issn = {01663615},
   journal = {Computers in Industry},
   keywords = {Cloud computing,Fault tolerance,Faults and failures,Survey},
   month = {8},
   pages = {156-172},
   publisher = {Elsevier B.V.},
   title = {Fault tolerance in cloud computing environment: A systematic survey},
   volume = {99},
   year = {2018},
}
@misc{Ghaffari2015,
   abstract = {With the advent of many-core architectures, scalability is a key property for programming languages. Actor-based frameworks like Erlang are fundamentally scalable, but in practice they have some scalability limitations. The RELEASE project aims to scale the Erlang's radical concurrency-oriented programming paradigm to build reliable general-purpose software, such as server-based systems, on emergent commodity architectures with 10 4 cores. The RELEASE consortium works to scale Erlang at the virtual machine, language level, infrastructure levels, and to supply profiling and refactoring tools. This research contributes to the RELEASE project at the language level. Firstly, we study the provision of scalable persistent storage options for Erlang. We articulate the requirements for scalable and available persistent storage, and evaluate four popular Erlang DBMSs against these requirements. We investigate the scalability limits of the Riak NoSQL DBMS using Basho Bench up to 100 nodes on the Kalkyl cluster and establish for the first time scientifically the scalability limit of Riak as 60 nodes, thereby confirming developer folklore. We design and implement DE-Bench, a scalable fault-tolerant peer-to-peer benchmarking tool that measures the throughput and latency of distributed Erlang commands on a cluster of Erlang nodes. We employ DE-Bench to investigate the scalability limits of distributed Erlang on up to 150 nodes and 1200 cores. Our results demonstrate that the frequency of global commands limits the scalability of distributed Erlang. We also show that distributed Erlang scales linearly up to 150 nodes and 1200 cores with relatively heavy data and computation loads when no global commands are used. As part of the RELEASE project, the Glasgow University team has developed Scalable Distributed Erlang (SD Erlang) to address the scalability limits of distributed Erlang. We evaluate SD Erlang by designing and implementing the first ever demonstrators for SD Erlang, i.e. DE-Bench, Orbit and Ant Colony Optimisation(ACO). We employ DE-Bench to evaluate the performance and scalability of group operations in SD-Erlang up to 100 nodes. Our results show that the alternatives SD-Erlang offers for global commands (i.e. group commands) scale linearly up to 100 nodes. We also develop and evaluate an SD-Erlang implementation of Orbit, a symbolic computing kernel and a generalization of a transitive closure computation. Our evaluation results show that SD Erlang Orbit outperforms the distributed Erlang Orbit on 160 nodes and 1280 cores. Moreover, we develop a reliable distributed version of ACO and show that the reliability of ACO limits its scalability in traditional distributed Er-lang. We use SD-Erlang to improve the scalability of the reliable ACO by eliminating global commands and avoiding full mesh connectivity between nodes. We show that SD Erlang reduces the network traffic between nodes in an Erlang cluster effectively.},
   author = {Amir Ghaffari},
   isbn = {2011287510},
   institution = {University of Glasgow},
   month = {10},
   title = {THE SCALABILITY OF RELIABLE COMPUTATION IN ERLANG AMIR GHAFFARI SUBMITTED IN FULFILMENT OF THE REQUIREMENTS FOR THE DEGREE OF},
   year = {2015},
}
@inproceedings{Barrio2024,
   abstract = {We describe the design and implementation of Scheduler, a new library for Elixir which provides a user-level scheduler. The goal is to improve the control over scheduling decisions, i.e., which process runs at which time, in order to obtain executions that are more random, but which are also repeatable and modifiable, and which moreover provide a detailed explanation of the scheduling decisions taken. This work is inspired by the Pulse user-level scheduler for Erlang programs, as well as other related tools. Our library is agnostic regarding what other testing/execution/formal verification tool uses the scheduler, and instruments Elixir code running under the scheduler through use of the Elixir macro facility. Moreover, the library provides a number of algorithms to explore the state space of the concurrent programs under study, including random search, depth-first search (potentially capable of exploring the whole state space of the program-under-study), and a novel search algorithm which selects schedules randomly. As an example the Scheduler library is applied to the task of checking whether a number of snapshot algorithms are correct.},
   author = {Luis Eduardo Bueso De Barrio and Lars Åke Fredlund and Clara Benac Earle and Ángel Herranz and Julio Mariño},
   doi = {10.1145/3677995.3678195},
   isbn = {9798400710988},
   booktitle = {Erlang 2024 - Proceedings of the 23rd ACM SIGPLAN International Workshop on Erlang, Co-located with: ICFP 2024},
   keywords = {Elixir,Model Checking,Program Scheduling,Testing},
   month = {8},
   pages = {67-75},
   publisher = {Association for Computing Machinery, Inc},
   title = {Controlled Scheduling of Concurrent Elixir Programs},
   year = {2024},
}
@inproceedings{Guo2020,
   abstract = {MPI has been ubiquitously deployed in flagship HPC systems aiming to accelerate distributed scientific applications running on tens of hundreds of processes and compute nodes. Maintaining the correctness and integrity of MPI application execution is critical, especially for safety-critical scientific applications. Therefore, a collection of effective MPI fault tolerance techniques have been proposed to enable MPI application execution to efficiently resume from system failures. However, there is no structured way to study and compare different MPI fault tolerance designs, so to guide the selection and development of efficient MPI fault tolerance techniques for distinct scenarios. To solve this problem, we design, develop, and evaluate a benchmark suite called MATCH to characterize, research, and comprehensively compare different combinations and configurations of MPI fault tolerance designs. Our investigation derives useful findings: (1) Reinit recovery in general performs better than ULFM recovery; (2) Reinit recovery is independent of the scaling size and the input problem size, whereas ULFM recovery is not; (3) Using Reinit recovery with FTI checkpointing is a highly efficient fault tolerance design. MATCH code is available at https://github.com/kakulo/MPI-FT-Bench.},
   author = {Luanzheng Guo and Giorgis Georgakoudis and Konstantinos Parasyris and Ignacio Laguna and Dong Li},
   doi = {10.1109/IISWC50251.2020.00015},
   isbn = {9781728176451},
   booktitle = {Proceedings - 2020 IEEE International Symposium on Workload Characterization, IISWC 2020},
   month = {10},
   pages = {60-71},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {MATCH: An MPI Fault Tolerance Benchmark Suite},
   year = {2020},
}
@article{Beschastnikh2020,
   abstract = {Distributed systems pose unique challenges for software developers. Understanding the system's communication topology and reasoning about concurrent activities of system hosts can be difficult. The standard approach, analyzing system logs, can be a tedious and complex process that involves reconstructing a system log from multiple hosts' logs, reconciling timestamps among hosts with non-synchronized clocks, and understanding what took place during the execution encoded by the log. This article presents a novel approach for tackling three tasks frequently performed during analysis of distributed system executions: (1) understanding the relative ordering of events, (2) searching for specific patterns of interaction between hosts, and (3) identifying structural similarities and differences between pairs of executions. Our approach consists of XVector, which instruments distributed systems to capture partial ordering information that encodes the happens-before relation between events, and ShiViz, which processes the resulting logs and presents distributed system executions as interactive time-space diagrams. Two user studies with a total of 109 students and a case study with 2 developers showed that our method was effective, helping participants answer statistically significantly more system-comprehension questions correctly, with a very large effect size.},
   author = {Ivan Beschastnikh and Perry Liu and Albert Xing and Patty Wang and Yuriy Brun and Michael D. Ernst},
   doi = {10.1145/3375633},
   issn = {15577392},
   issue = {2},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {Distributed systems,log analysis,program comprehension},
   month = {3},
   publisher = {Association for Computing Machinery},
   title = {Visualizing Distributed System Executions},
   volume = {29},
   year = {2020},
}
@book{Vitillo2021,
   author = {Roberto Vitillo},
   isbn = {1838430202},
   title = {Understanding Distributed Systems: What every developer should know about large distributed applications},
   year = {2021},
}
@book{Kleppmann2017,
   author = {Martin Kleppmann},
   isbn = {978-1449373320},
   title = {Designing Data Intensive Applications},
   year = {2017},
}
@misc{Lamport1978,
   abstract = {The concept of one event happening before another in a distributed system is examined , and is shown to define a partial ordering of the events. A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. The use of the total ordering is illustrated with a method for solving synchronization problems. The algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become. General permission to make fair use in teaching or research of all or part of this material is granted to individual readers and to nonprofit libraries acting for them provided that ACM's copyright notice is given and that reference is made to the publication, to its date of issue, and to the fact that reprinting privileges were granted by permission of the Association for Computing Machinery. To otherwise reprint a figure, table, other substantial excerpt, or the entire work requires specific permission as does republication, or systematic or multiple reproduction.},
   author = {Leslie Lamport},
   doi = {https://doi.org/10.1145/359545.359563},
   issue = {7},
   journal = {Communications of the ACM},
   keywords = {Compositor: Windfall Software,Publisher: Association for Computing Machinery},
   title = {Time, Clocks, and the Ordering of Events in a Distributed System and the Ordering of Events in a Distributed System},
   volume = {21},
   year = {1978},
}
@inproceedings{Naik2021,
   abstract = {The design of distributed systems in multiple clouds have been gaining popularity due to various benefits of the multi-cloud infrastructure such as minimizing vendor lock-in, data loss and downtime. Nonetheless, this multi-cloud infrastructure also poses several challenges such as compatibility, interoperability, complex provisioning and configuration due to the variation in technologies and services of each cloud provider. Consequently, it is a tedious task to design distributed systems in multiple clouds. Virtualization is regarded as the base technology of the cloud and therefore, most cloud-based distributed systems are based on it. Nevertheless, virtual machines require substantial resources and cause several issues across multiple clouds such as provisioning, configuration management, load balancing and migration. Docker Swarm is a container-based clustering tool that resolves some of these issues and supports the design of distributed systems in multiple clouds. It has also incorporated several inbuilt attributes of the distributed system, however, it is still evolving. This paper initially presents the simulated development of a Docker Swarm-based distributed system which can be easily replicated in multiple clouds. Subsequently, based on the simulated Docker Swarm-based distributed system, it performs an evaluation of several attributes of this distributed system such as high availability and fault tolerance; automatic scalability, load balancing and maintainability of services; and scalability of large clusters.},
   author = {Nitin Naik},
   doi = {10.1109/SysCon48628.2021.9447123},
   isbn = {9781665444392},
   booktitle = {15th Annual IEEE International Systems Conference, SysCon 2021 - Proceedings},
   keywords = {Container,Containerization,Distributed System,Docker Swarm,Fault Tolerance,High Availability,Load Balancing,Maintainability,Multiple Clouds,Scalability,Virtual Machine,Virtualization},
   month = {4},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Performance Evaluation of Distributed Systems in Multiple Clouds using Docker Swarm},
   year = {2021},
}
@article{Sari2015,
   abstract = {The use of technology has increased vastly and today computer systems are interconnected via different communication medium. The use of distributed systems in our day to day activities has solely improved with data distributions. This is because distributed systems enable nodes to or-ganise and allow their resources to be used among the connected systems or devices that make people to be integrated with geographically distributed computing facilities. The distributed sys-tems may lead to lack of service availability due to multiple system failures on multiple failure points. This article highlights the different fault tolerance mechanism in distributed systems used to prevent multiple system failures on multiple failure points by considering replication, high re-dundancy and high availability of the distributed services.},
   author = {Arif Sari and Murat Akkaya},
   doi = {10.4236/ijcns.2015.812042},
   issn = {1913-3715},
   issue = {12},
   journal = {International Journal of Communications, Network and System Sciences},
   pages = {471-482},
   publisher = {Scientific Research Publishing, Inc,},
   title = {Fault Tolerance Mechanisms in Distributed Systems},
   volume = {08},
   year = {2015},
}
@article{Lindsay2021,
   abstract = {Distributed systems have been an active field of research for over 60 years, and has played a crucial role in computer science, enabling the invention of the Internet that underpins all facets of modern life. Through technological advancements and their changing role in society, distributed systems have undergone a perpetual evolution, with each change resulting in the formation of a new paradigm. Each new distributed system paradigm—of which modern prominence include cloud computing, Fog computing, and the Internet of Things (IoT)—allows for new forms of commercial and artistic value, yet also ushers in new research challenges that must be addressed in order to realize and enhance their operation. However, it is necessary to precisely identify what factors drive the formation and growth of a paradigm, and how unique are the research challenges within modern distributed systems in comparison to prior generations of systems. The objective of this work is to study and evaluate the key factors that have influenced and driven the evolution of distributed system paradigms, from early mainframes, inception of the global inter-network, and to present contemporary systems such as edge computing, Fog computing and IoT. Our analysis highlights assumptions that have driven distributed systems appear to be changing, including (1) an accelerated fragmentation of paradigms driven by commercial interests and physical limitations imposed by the end of Moore’s law, (2) a transition away from generalized architectures and frameworks towards increasing specialization, and (3) each paradigm architecture results in some form of pivoting between centralization and decentralization coordination. Finally, we discuss present day and future challenges of distributed research pertaining to studying complex phenomena at scale and the role of distributed systems research in the context of climate change.},
   author = {Dominic Lindsay and Sukhpal Singh Gill and Daria Smirnova and Peter Garraghan},
   doi = {10.1007/s00607-020-00900-y},
   issn = {14365057},
   issue = {8},
   journal = {Computing},
   keywords = {Computing systems,Distributed computing,Evolution,Green computing},
   month = {8},
   pages = {1859-1878},
   publisher = {Springer},
   title = {The evolution of distributed computing systems: from fundamental to new frontiers},
   volume = {103},
   year = {2021},
}
@book{Coulouris2012,
   author = {George Coulouris and Jean Dollimore and Tim Kindberg and Gordon Blair},
   isbn = {978-0-13-214301-1},
   title = {Distributed Systems - Concepts and Design},
   year = {2012},
}
@misc{Cachin2012,
   author = {Christian Cachin and Rachid Guerraoui and Luís Rodrigues},
   title = {Introduction to Reliable and Secure Distributed Programming • Introduction to},
   year = {2011},
}
@misc{Brendan2018,
   author = {Brendan Burns},
   isbn = {978-1-492-03177-2},
   title = {Designing Distributed Systems Patterns and Paradigms for scalable, reliable services},
   year = {2018},
}
@book{Ledmi2018,
   abstract = {"Part Number: CFP18PAD-ART.". },
   author = {Mohamed. Amroune and Makhlouf. Derdour and Ahmed. Ahmim},
   isbn = {9781538642382},
   publisher = {IEEE},
   title = {Fault Tolerance in Distributed Systems: A Survey},
   year = {2018},
}
@article{Tanenbaum2016,
   abstract = {Distributed systems are by now commonplace, yet remain an often difficult area of research. This is partly explained by the many facets of such systems and the inherent difficulty to isolate these facets from each other. In this paper we provide a brief overview of distributed systems: what they are, their general design goals, and some of the most common types.},
   author = {Maarten van Steen and Andrew S. Tanenbaum},
   doi = {10.1007/s00607-016-0508-7},
   issn = {0010485X},
   issue = {10},
   journal = {Computing},
   keywords = {Distributed computer system,Networked computer systems},
   month = {10},
   pages = {967-1009},
   publisher = {Springer-Verlag Wien},
   title = {A brief introduction to distributed systems},
   volume = {98},
   year = {2016},
}
@article{Banatre1991,
   author = {Michel Banatre},
   doi = {10.1109/ICSE.1991.130643},
   title = {Hiding distribution in distributed systems},
   year = {1991},
}
@inproceedings{Ahmed2013,
   abstract = {Software's reliability in distributed systems has always been a major concern for all stake holders especially for application's vendors and its users. Various models have been produced to assess or predict reliability of large scale distributed applications including e-government, e-commerce, multimedia services, and end-to-end automotive solutions, but reliability issues with these systems still exists. Ensuring distributed system's reliability in turns requires examining reliability of each individual component or factors involved in enterprise distributed applications before predicting or assessing reliability of whole system, and Implementing transparent fault detection and fault recovery scheme to provide seamless interaction to end users. For this reason we have analyzed in detail existing reliability methodologies from viewpoint of examining reliability of individual component and explained why we still need a comprehensive reliability model for applications running in distributed system. In this paper we have described detailed technical overview of research done in recent years in analyzing and predicting reliability of large scale distributed applications in four parts. We first described some pragmatic requirements for highly reliable systems and highlighted significance and various issues of reliability in different computing environment such as Cloud Computing, Grid Computing, and Service Oriented Architecture. Then we elucidated certain possible factors and various challenges that are nontrivial for highly reliable distributed systems, including fault detection, recovery and removal through testing or various replication techniques. Later we scrutinize various research models which synthesize significant solutions to tackle possible factors and various challenges in predicting as well as measuring reliability of software applications in distributed systems. At the end of this paper we have discussed limitations of existing models and proposed future work for predicting and analyzing reliability of distributed applications in real environment in the light of our analysis. © 2013 Elsevier Inc.},
   author = {Waseem Ahmed and Yong Wei Wu},
   doi = {10.1016/j.jcss.2013.02.006},
   issn = {10902724},
   issue = {8},
   booktitle = {Journal of Computer and System Sciences},
   keywords = {Assessment,Fault tolerant,Keyword,Reliability prediction},
   pages = {1243-1255},
   publisher = {Academic Press Inc.},
   title = {A survey on reliability in distributed systems},
   volume = {79},
   year = {2013},
}
@misc{Mushtaq2022,
   author = {Aisha Mushtaq},
   title = {Fault Tolerance in Distributed Systems},
   url = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2022/EECS-2022-44.html},
   year = {2022},
}
@inproceedings{Yuan2020,
   abstract = {Despite their wide deployment, distributed systems remain notoriously hard to reason about. Unexpected interleavings of concurrent operations and failures may lead to undefined behaviors and cause serious consequences. We present Morpheus, the first concurrency testing tool leveraging partial order sampling, a randomized testing method formally analyzed and empirically validated to provide strong probabilistic guarantees of error-detection, for real-world distributed systems. Morpheus introduces conflict analysis to further improve randomized testing by predicting and focusing on operations that affect the testing result. Inspired by the recent shift in building distributed systems using higher-level languages and frameworks, Morpheus targets Erlang. Evaluation on four popular distributed systems in Erlang including RabbitMQ, a message broker service, and Mnesia, a distributed database in the Erlang standard libraries, shows that Morpheus is effective: It found previously unknown errors in every system checked, 11 total, all of which are flaws in their core protocols that may cause deadlocks, unexpected crashes, or inconsistent states.},
   author = {Xinhao Yuan and Junfeng Yang},
   doi = {10.1145/3373376.3378484},
   isbn = {9781450371025},
   booktitle = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
   keywords = {Conflict analysis,Distributed systems,Partial order sampling,Partial-order reduction,Randomized testing},
   month = {3},
   pages = {1141-1156},
   publisher = {Association for Computing Machinery},
   title = {Effective concurrency testing for distributed systems},
   year = {2020},
}
@article{Glabbeek2008,
   abstract = {When considering distributed systems, it is a central issue how to deal with interactions between components. In this paper, we investigate the paradigms of synchronous and asynchronous interaction in the context of distributed systems. We investigate to what extent or under which conditions synchronous interaction is a valid concept for specification and implementation of such systems. We choose Petri nets as our system model and consider different notions of distribution by associating locations to elements of nets. First, we investigate the concept of simultaneity which is inherent in the semantics of Petri nets when transitions have multiple input places. We assume that tokens may only be taken instantaneously by transitions on the same location. We exhibit a hierarchy of `asynchronous' Petri net classes by different assumptions on possible distributions. Alternatively, we assume that the synchronisations specified in a Petri net are crucial system properties. Hence transitions and their preplaces may no longer placed on separate locations. We then answer the question which systems may be implemented in a distributed way without restricting concurrency, assuming that locations are inherently sequential. It turns out that in both settings we find semi-structural properties of Petri nets describing exactly the problematic situations for interactions in distributed systems.},
   author = {Rob van Glabbeek and Ursula Goltz and Jens-Wolfhard Schicke},
   month = {12},
   title = {On Synchronous and Asynchronous Interaction in Distributed Systems},
   url = {http://arxiv.org/abs/0901.0048},
   year = {2008},
}
@inproceedings{Dragoi2015,
   abstract = {Fault-tolerant distributed algorithms play an important role in many critical/high-availability applications. These algorithms are notoriously difficult to implement correctly, due to asynchronous communication and the occurrence of faults, such as the network dropping messages or computers crashing. Nonetheless there is surprisingly little language and verification support to build distributed systems based on fault-tolerant algorithms. In this paper, we present some of the challenges that a designer has to overcome to implement a fault-tolerant distributed system. Then we review different models that have been proposed to reason about distributed algorithms and sketch how such a model can form the basis for a domain-specific programming language. Adopting a high-level programming model can simplify the programmer's life and make the code amenable to automated verification, while still compiling to efficiently executable code. We conclude by summarizing the current status of an ongoing language design and implementation project that is based on this idea.},
   author = {Cezara Dragoi and Thomas A. Henzinger and Damien Zufferey},
   doi = {10.4230/LIPIcs.SNAPL.2015.90},
   isbn = {9783939897804},
   issn = {18688969},
   booktitle = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Automated verification,Fault-tolerant distributed algorithms,Programming language},
   month = {5},
   pages = {90-102},
   publisher = {Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing},
   title = {The need for language support for fault-tolerant distributed systems},
   volume = {32},
   year = {2015},
}
@misc{Gilbert2012,
   abstract = {Almost twelve years ago, in 2000, Eric Brewer introduced the idea that there is a fundamental trade-off between consistency, availability, and partition tolerance. This trade-off, which has become known as the CAP Theorem, has been widely discussed ever since. In this paper, we review the CAP Theorem and situate it within the broader context of distributed computing theory. We then discuss the practical implications of the CAP Theorem, and explore some general techniques for coping with the inherent trade-offs that it implies.},
   author = {Seth Gilbert and Nancy A Lynch},
   doi = {10.1109/MC.2011.389},
   title = {Perspectives on the CAP Theorem},
   year = {2012},
}
@article{Gill2024,
   abstract = {Over the past six decades, the computing systems field has experienced significant transformations, profoundly impacting society with transformational developments, such as the Internet and the commodification of computing. Underpinned by technological advancements, computer systems, far from being static, have been continuously evolving and adapting to cover multifaceted societal niches. This has led to new paradigms such as cloud, fog, edge computing, and the Internet of Things (IoT), which offer fresh economic and creative opportunities. Nevertheless, this rapid change poses complex research challenges, especially in maximizing potential and enhancing functionality. As such, to maintain an economical level of performance that meets ever-tighter requirements, one must understand the drivers of new model emergence and expansion, and how contemporary challenges differ from past ones. To that end, this article investigates and assesses the factors influencing the evolution of computing systems, covering established systems and architectures as well as newer developments, such as serverless computing, quantum computing, and on-device AI on edge devices. Trends emerge when one traces technological trajectory, which includes the rapid obsolescence of frameworks due to business and technical constraints, a move towards specialized systems and models, and varying approaches to centralized and decentralized control. This comprehensive review of modern computing systems looks ahead to the future of research in the field, highlighting key challenges and emerging trends, and underscoring their importance in cost-effectively driving technological progress.},
   author = {Sukhpal Singh Gill and Huaming Wu and Panos Patros and Carlo Ottaviani and Priyansh Arora and Victor Casamayor Pujol and David Haunschild and Ajith Kumar Parlikad and Oktay Cetinkaya and Hanan Lutfiyya and Vlado Stankovski and Ruidong Li and Yuemin Ding and Junaid Qadir and Ajith Abraham and Soumya K. Ghosh and Houbing Herbert Song and Rizos Sakellariou and Omer Rana and Joel J. P. C. Rodrigues and Salil S. Kanhere and Schahram Dustdar and Steve Uhlig and Kotagiri Ramamohanarao and Rajkumar Buyya},
   doi = {10.1016/j.teler.2024.100116},
   month = {1},
   title = {Modern Computing: Vision and Challenges},
   url = {http://arxiv.org/abs/2401.02469 http://dx.doi.org/10.1016/j.teler.2024.100116},
   year = {2024},
}
@misc{Cao2020,
   abstract = {With the rapid development of the Internet of Everything (IoE), the number of smart devices connected to the Internet is increasing, resulting in large-scale data, which has caused problems such as bandwidth load, slow response speed, poor security, and poor privacy in traditional cloud computing models. Traditional cloud computing is no longer sufficient to support the diverse needs of today's intelligent society for data processing, so edge computing technologies have emerged. It is a new computing paradigm for performing calculations at the edge of the network. Unlike cloud computing, it emphasizes closer to the user and closer to the source of the data. At the edge of the network, it is lightweight for local, small-scale data storage and processing. This article mainly reviews the related research and results of edge computing. First, it summarizes the concept of edge computing and compares it with cloud computing. Then summarize the architecture of edge computing, keyword technology, security and privacy protection, and finally summarize the applications of edge computing.},
   author = {Keyan Cao and Yefan Liu and Gongjie Meng and Qimeng Sun},
   doi = {10.1109/ACCESS.2020.2991734},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Edge computing,Internet of Things,cloud computing},
   pages = {85714-85728},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {An Overview on Edge Computing Research},
   volume = {8},
   year = {2020},
}
@article{Yongkang2023,
   abstract = {Serverless computing is growing in popularity by virtue of its lightweight and simplicity of management. It achieves these merits by reducing the granularity of the computing unit to the function level. Specifically, serverless allows users to focus squarely on the function itself while leaving other cumbersome management and scheduling issues to the platform provider, who is responsible for striking a balance between high-performance scheduling and low resource cost. In this article, we conduct a comprehensive survey of serverless computing with a particular focus on its infrastructure characteristics. Whereby some existing challenges are identified, and the associated cutting-edge solutions are analyzed. With these results, we further investigate some typical open-source frameworks and study how they address the identified challenges. Given the great advantages of serverless computing, it is expected that its deployment would dominate future cloud platforms. As such, we also envision some promising research opportunities that need to be further explored in the future. We hope that our work in this article can inspire those researchers and practitioners who are engaged in related fields to appreciate serverless computing, thereby setting foot in this promising area and making great contributions to its development.},
   author = {Yongkang Li and Yanying Lin and Yang Wang and Kejiang Ye and Chengzhong Xu},
   doi = {10.1109/TSC.2022.3166553},
   issn = {19391374},
   issue = {2},
   journal = {IEEE Transactions on Services Computing},
   keywords = {FaaS and BaaS,Survey,isolation,scheduling,serverless computing,startup latency},
   month = {3},
   pages = {1522-1539},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Serverless Computing: State-of-the-Art, Challenges and Opportunities},
   volume = {16},
   year = {2023},
}
@inproceedings{Gusev2021,
   abstract = {A lot of research and development activities have been referencing to edge and dew computing solutions for IoT applications, but without determining the deep distinction between these two architectural approaches. Furthermore, there is no clear explanation if dew computing is a special case of edge computing or the opposite. In this paper, we analyze the features of post-cloud architectures to build an IoT solution and clarify the main differences between dew and edge computing approaches. Although the provided analysis covers IoT solutions, still the same principles can be applied more generally.},
   author = {Marjan Gusev},
   doi = {10.1109/COMPSAC51774.2021.00269},
   isbn = {9781665424639},
   booktitle = {Proceedings - 2021 IEEE 45th Annual Computers, Software, and Applications Conference, COMPSAC 2021},
   keywords = {Cloudlet,Dew computing,Edge computing,Fog computing,Mobile edge computing},
   month = {7},
   pages = {1795-1800},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {What makes dew computing more than edge computing for internet of things},
   year = {2021},
}
@article{Adbelfattah2023,
   abstract = {Understanding software systems written by others is often challenging. When we want to assess systems to reason about them, i.e., to understand dependencies, analyze evolution trade-offs, or to verify conformance to the original blueprint, we must invest broad efforts. This becomes difficult when considering decentralized systems. Microservice-based systems are mainstream these days; however, to observe, understand, and manage these systems and their properties, we are missing fundamental tools that would derive various simplified system abstract perspectives. Microservices architecture characteristics yield many advantages to system operation; however, they bring challenges to their development and deployment lifecycles. Microservices urge a system-centric perspective to better reason about the system evolution and its quality attributes. This process review paper considers the current system analysis approaches and their possible alignment with automated system assessment or with human-centered approaches. We outline the necessary steps to accomplish holistic reasoning in decentralized microservice systems. As a contribution, we provide a roadmap for analysis and reasoning in microservice-based systems and suggest that various process phases can be decoupled through the introduction of system intermediate representation as the trajectory to provide various system-centered perspectives to analyze various system aspects. Furthermore, we cover different technical-based reasoning strategies and metrics in addition to the human-centered reasoning addressed through alternative visualization approaches. Finally, a system evolution is discussed from the perspective of such a reasoning process to illustrate the impact analysis evaluation over system changes.},
   author = {Amr S. Abdelfattah and Tomas Cerny},
   doi = {10.3390/app13031838},
   issn = {20763417},
   issue = {3},
   journal = {Applied Sciences (Switzerland)},
   keywords = {architecture degradation,architecture reconstruction,evolution,microservices visualization},
   month = {2},
   publisher = {MDPI},
   title = {Roadmap to Reasoning in Microservice Systems: A Rapid Review},
   volume = {13},
   year = {2023},
}
@inbook{Strigini2012,
   abstract = {To assess in quantitative terms the “resilience” of systems, it is necessary to ask first what is meant by “resilience”, whether it is a single attribute or several, which measure or measures appropriately characterise it. This chapter covers: the technical meanings that the word “resilience” has assumed, and its role in the debates about how best to achieve reliability, safety, etc.; the different possible measures for the attributes that the word designates, with their different pros and cons in terms of ease of empirical assessment and suitability for supporting prediction and decision making; the similarity between these concepts, measures and attached problems in various fields of engineering, and how lessons can be propagated between them.},
   author = {Lorenzo Strigini},
   doi = {10.1007/978-3-642-29032-9_1},
   journal = {Resilience Assessment and Evaluation of Computing Systems},
   pages = {3-24},
   publisher = {Springer Berlin Heidelberg},
   title = {Fault Tolerance and Resilience: Meanings, Measures and Assessment},
   year = {2012},
}
@misc{Isukapalli2024,
   abstract = {Fault tolerance is becoming increasingly important for upcoming exascale systems, supporting distributed data processing, due to the expected decrease in the Mean Time Between Failures (MTBF). To ensure the availability, reliability, dependability, and performance of the system, addressing the fault tolerance challenge is crucial. It aims to keep the distributed system running at a reduced capacity while avoiding complete data loss, even in the presence of faults, with minimal impact on system performance. This comprehensive survey aims to provide a detailed understanding of the importance of fault tolerance in distributed systems, including a classification of faults, errors, failures, and fault-tolerant techniques (reactive, proactive, and predictive). We collected a corpus of 490 papers published from 2014 to 2023 by searching in Scopus, IEEE Xplore, Springer, and ACM digital library databases. After a systematic review, 17 reactive models, 17 proactive models, and 14 predictive models were shortlisted and compared. A taxonomy of ideas behind the proposed models was also created for each of these categories of fault-tolerant solutions. Additionally, it examines how fault tolerance capability is incorporated into popular big data processing tools such as Apache Hadoop, Spark, and Flink. Finally, promising future research directions in this domain are discussed.},
   author = {Sucharitha Isukapalli and Satish Narayana Srirama},
   doi = {10.1016/j.cosrev.2024.100660},
   issn = {15740137},
   journal = {Computer Science Review},
   keywords = {Distributed data analytics,Fault-tolerance,Machine learning,MapReduce,Reactive and proactive models,Reliability},
   month = {8},
   publisher = {Elsevier Ireland Ltd},
   title = {A systematic survey on fault-tolerant solutions for distributed data analytics: Taxonomy, comparison, and future directions},
   volume = {53},
   year = {2024},
}
@article{Hussein2021,
   abstract = {The use of technology has grown dramatically, and computer systems are now interconnected via various communication mediums. The use of distributed systems (DS) in our daily activities has only gotten better with data distributions. This is due to the fact that distributed systems allow nodes to arrange and share their resources across linked systems or devices, allowing humans to be integrated with geographically spread computer capacity. Due to multiple system failures at multiple failure points, distributed systems may result in a lack of service availability. to avoid multiple system failures at multiple failure points by using fault tolerance (FT) techniques in distributed systems to ensure replication, high redundancy, and high availability of distributed services. In this paper shows ease fault tolerance systems, its requirements, and explain about distributed system. Also, discuss distributed system architecture; furthermore, explain used techniques of fault tolerance, in additional that review some recent literature on fault tolerance in distributed systems and finally, discuss and compare the fault tolerance literature.},
   author = {Arshad A. Hussein and Adel AL-zebari and Naaman Omar and Karwan Jameel Merceedi and Abdulraheem Jamil Ahmed and Nareen O. M. Salim and Sheren Sadiq Hasan and Shakir Fattah Kak and Ibrahim Mahmood Ibrahim and Hajar Maseeh Yasin and Azar Abid Salih},
   doi = {10.9734/ajrcos/2021/v11i430268},
   journal = {Asian Journal of Research in Computer Science},
   month = {9},
   pages = {19-34},
   publisher = {Sciencedomain International},
   title = {State of Art Survey for Fault Tolerance Feasibility in Distributed Systems},
   year = {2021},
}
@article{Noor2019,
   abstract = {Distributed systems mainly provide access to a large amount of data and computational resources through a wide range of interfaces. Besides its dynamic nature, which means that resources may enter and leave the environment at any time, many distributed systems applications will be running in an environment where faults are more likely to occur due to their ever-increasing scales and the complexity. Due to diverse faults and failures conditions, fault tolerance has become a critical element for distributed computing in order for the system to perform its function correctly even in the present of faults. Replication techniques primarily concentrate on the two fault tolerance manners precisely masking the failures as well as reconfigure the system in response. This paper presents a brief survey on different replication techniques such as Read One Write All (ROWA), Quorum Consensus (QC), Tree Quorum (TQ) Protocol, Grid Configuration (GC) Protocol, Two-Replica Distribution Techniques (TRDT), Neighbour Replica Triangular Grid (NRTG) and Neighbour Replication Distributed Techniques (NRDT). These techniques have its own redeeming features and shortcoming which forms the subject matter of this survey.},
   author = {Ahmad Shukri Mohd Noor and Nur Farhah Mat Zian and Fatin Nurhanani M. Shaiful Bahri},
   doi = {10.11591/ijece.v9i2.pp1298-1303},
   issn = {20888708},
   issue = {2},
   journal = {International Journal of Electrical and Computer Engineering},
   keywords = {Distributed computing,Distributed systems,Fault failure recovery,High availability,Replication technique},
   month = {4},
   pages = {1298-1303},
   publisher = {Institute of Advanced Engineering and Science},
   title = {Survey on replication techniques for distributed system},
   volume = {9},
   year = {2019},
}
@article{Reghenzani2023,
   abstract = {Tolerating hardware faults in modern architectures is becoming a prominent problem due to the miniaturization of the hardware components, their increasing complexity, and the necessity to reduce costs. Software-Implemented Hardware Fault Tolerance approaches have been developed to improve system dependability regarding hardware faults without resorting to custom hardware solutions. However, these come at the expense of making the satisfaction of the timing constraints of the applications/activities harder from a scheduling standpoint. This article surveys the current state-of-the-art of fault tolerance approaches when used in the context of real-time systems, identifying the main challenges and the cross-links between these two topics. We propose a joint scheduling-failure analysis model that highlights the formal interactions among software fault tolerance mechanisms and timing properties. This model allows us to present and discuss many open research questions with the final aim to spur future research activities.},
   author = {Federico Reghenzani and Zhishan Guo and William Fornaciari},
   doi = {10.1145/3589950},
   issn = {15577341},
   issue = {14},
   journal = {ACM Computing Surveys},
   keywords = {Real-time,fault-tolerance,mixed-criticality},
   month = {12},
   publisher = {Association for Computing Machinery},
   title = {Software Fault Tolerance in Real-Time Systems: Identifying the Future Research Questions},
   volume = {55},
   year = {2023},
}
@misc{Cutajar2023,
   author = {James Cutajar},
   isbn = {9781633438385},
   title = {Learn Concurrent Programming with Go},
   year = {2023},
}
@article{Trinder2017,
   author = {Phil Trinder},
   title = {Scaling Reliably: Improving the
Scalability of the Erlang Distributed
Actor Platform},
   url = {https://ar5iv.labs.arxiv.org/html/1704.07234},
   year = {2017},
}
@book{Abraham2023,
   author = {Francisco Lopez-Sancho Abraham},
   isbn = {9781617299216},
   publisher = {Simon and Schuster},
   title = {Akka in Action, Second Edition},
   year = {2023},
}
@article{Srirama2021,
   abstract = {Future Internet of Things (IoT)-driven applications will move from the cloud-centric IoT model to the hybrid distributed processing model, known as Fog computing, where some of the involved computational tasks (e.g. real-time data analytics) are partially moved to the edge of the network to reduce latency and improve the network efficiency. In recent times, Fog computing has generated significant research interest for IoT applications, however, there is still a lack of ideal approach and framework for supporting parallel and fault-tolerant execution of the tasks while collectively utilizing the resource-constrained Fog devices. To address this issue, in this paper, we propose an Akka framework based on the Actor Model for designing and executing the distributed Fog applications. The Actor Model was conceived as a universal paradigm for concurrent computation with additional requirements such as resiliency and scalability, whereas, the Akka toolkit is a reference implementation of the model. Further, to dynamically deploy the distributed applications on the Fog networks, a Docker containerization approach is used. To validate the proposed actor-based framework, a wireless sensor network case study is designed and implemented for demonstrating the feasibility of conceiving applications on the Fog networks. Besides that, a detailed analysis is produced for showing the performance and parallelization efficiency of the proposed model on the resource-constrained gateway and Fog devices.},
   author = {Satish Narayana Srirama and Freddy Marcelo Surriabre Dick and Mainak Adhikari},
   doi = {10.1016/j.future.2020.12.011},
   issn = {0167739X},
   journal = {Future Generation Computer Systems},
   keywords = {Actor programming model,Akka toolkit,Distributed processing,Docker,Fog Computing,Internet of Things},
   month = {4},
   pages = {439-452},
   publisher = {Elsevier B.V.},
   title = {Akka framework based on the Actor model for executing distributed Fog Computing applications},
   volume = {117},
   year = {2021},
}
@article{Castagna2023,
   abstract = {Elixir is a dynamically-typed functional language running on the Erlang Virtual Machine, designed for building scalable and maintainable applications. Its characteristics have earned it a surging adoption by hundreds of industrial actors and tens of thousands of developers. Static typing seems nowadays to be the most important request coming from the Elixir community. We present a gradual type system we plan to include in the Elixir compiler, outline its characteristics and design principles, and show by some short examples how to use it in practice. Developing a static type system suitable for Erlang's family of languages has been an open research problem for almost two decades. Our system transposes to this family of languages a polymorphic type system with set-theoretic types and semantic subtyping. To do that, we had to improve and extend both semantic subtyping and the typing techniques thereof, to account for several characteristics of these languages -- and of Elixir in particular -- such as the arity of functions, the use of guards, a uniform treatment of records and dictionaries, the need for a new sound gradual typing discipline that does not rely on the insertion at compile time of specific run-time type-tests but, rather, takes into account both the type tests performed by the virtual machine and those explicitly added by the programmer. The system presented here is "gradually" being implemented and integrated in Elixir, but a prototype implementation is already available. The aim of this work is to serve as a longstanding reference that will be used to introduce types to Elixir programmers, as well as to hint at some future directions and possible evolutions of the Elixir language.},
   author = {Giuseppe Castagna and Guillaume Duboc and José Valim},
   doi = {10.22152/programming-journal.org/2024/8/4},
   issue = {2},
   journal = {Art, Science, and Engineering of Programming},
   keywords = {Elixir,dynamiclanguages,set-theoretictypes,typesystems},
   month = {6},
   pages = {4:1-4:39},
   publisher = {AOSA Inc.},
   title = {The Design Principles of the Elixir Type System},
   volume = {8},
   url = {http://arxiv.org/abs/2306.06391 http://dx.doi.org/10.22152/programming-journal.org/2024/8/4},
   year = {2023},
}
@article{Castagna2024,
   abstract = {Elixir is a dynamically-typed functional language running on the Erlang Virtual Machine, designed for building scalable and maintainable applications. Its characteristics have earned it a surging adoption by hundreds of industrial actors and tens of thousands of developers. Static typing seems nowadays stobe the most important request coming from the Elixir community. We present a gradual type system we plan to include in the Elixir compiler, outline its characteristics and design principles, and show by some short examples how to use it in practice. Developing a static type system suitable for Erlang’s family of languages has been an open research problem for almost two decades. Our system transposes to this family of languages a polymorphic type system with set-theoretic types and semantic subtyping.To do that,we had toimprove and extend both semantic subtyping and the typing techniques thereof, to account for several characteristics of these languages—and of Elixir in particular—such as the arity of functions, the use of guards, a uniform treatment of records and dictionaries, the need for a new sound gradual typing discipline that does not rely on the insertion at compile time of specific run-time type-tests but, rather, takes into account both the type tests performed by the virtual machine and those explicitly added by the programmer. The system presented here is “gradually” being implemented and integrated in Elixir, but a prototype implementation is already available. The aim of this work is to serve as a longstanding reference that will be used to introduce types to Elixir programmers, as well as to hint at some future directions and possible evolutions of the Elixir language.},
   author = {Giuseppe Castagna and Guillaume Duboc and José Valim},
   doi = {10.22152/programming-journal.org/2024/8/4},
   issn = {24737321},
   issue = {2},
   journal = {Art, Science, and Engineering of Programming},
   keywords = {Elixir,dynamiclanguages,set-theoretictypes,typesystems},
   pages = {4:1-4:39},
   publisher = {AOSA Inc.},
   title = {The Design Principles of the Elixir Type System},
   volume = {8},
   year = {2024},
}
@article{Hoare1983,
   abstract = {This paper suggests that input and output are basic primitives of programming and that parallel composition of communicating sequential processes is a fundamental program structuring method. When c...},
   author = {C. A.R. Hoare},
   doi = {10.1145/357980.358021},
   issn = {15577317},
   issue = {1},
   journal = {Communications of the ACM},
   keywords = {classes,concurrency,conditional critical regions,coroutines,data representations,guarded commands,input,iterative arrays,monitors,multiple entries,multiple exits,nondeterminacy,output,parallel programming,procedures,program structures,programming,programming languages,programming primitives,recursion},
   month = {1},
   pages = {100-106},
   publisher = {ACMPUB27New York, NY, USA},
   title = {Communicating sequential processes},
   volume = {26},
   url = {https://dl.acm.org/doi/10.1145/357980.358021},
   year = {1983},
}
@inproceedings{Chabbi2022,
   abstract = {The concurrent programming literature is rich with tools and techniques for data race detection. Less, however, has been known about real-world, industry-scale deployment, experience, and insights about data races. Golang (Go for short) is a modern programming language that makes concurrency a first-class citizen. Go offers both message passing and shared memory for communicating among concurrent threads. Go is gaining popularity in modern microservice-based systems. Data races in Go stand in the face of its emerging popularity. In this paper, using our industrial codebase as an example, we demonstrate that Go developers embrace concurrency and show how the abundance of concurrency alongside language idioms and nuances make Go programs highly susceptible to data races. Google's Go distribution ships with a built-in dynamic data race detector based on ThreadSanitizer. However, dynamic race detectors pose scalability and flakiness challenges; we discuss various software engineering trade-offs to make this detector work effectively at scale. We have deployed this detector in Uber's 46 million lines of Go codebase hosting 2100 distinct microservices, found over 2000 data races, and fixed over 1000 data races, spanning 790 distinct code patches submitted by 210 unique developers over a six-month period. Based on a detailed investigation of these data race patterns in Go, we make seven high-level observations relating to the complex interplay between the Go language paradigm and data races.},
   author = {Milind Chabbi and Murali Krishna Ramanathan},
   doi = {10.1145/3519939.3523720},
   isbn = {9781450392655},
   booktitle = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Data race,Dynamic analysis,Golang},
   month = {6},
   pages = {474-489},
   publisher = {Association for Computing Machinery},
   title = {A study of real-world data races in Golang},
   year = {2022},
}
@inproceedings{Paduraru2018,
   abstract = {Programming parallelism with shared memory raises some technical difficulties in synchronization and accessing memory in a thread-safe way. Most of the time the result is a trade-off between application's source code understandability, maintainability and error-prone on one side, and performance on the other side. This trade-off is even tighter when using low-level languages such as C++. The paper presents an open-source library for C++ that provides a Sequential Communicating Processes method for communication and synchronization, and overall, aims to simplify the shared memory parallelism development, make it more predictable and less error-prone, without sacrificing performance. The efficiency of the solution is proven through a set of concrete examples and benchmarks.},
   author = {Ciprian Paduraru and Marius Constantin Melemciuc},
   doi = {10.1109/ISPDC2018.2018.00030},
   isbn = {9781538653302},
   booktitle = {Proceedings - 17th International Symposium on Parallel and Distributed Computing, ISPDC 2018},
   keywords = {C++,CSP,Parallelism,channels},
   month = {8},
   pages = {157-163},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Parallelism in C++ Using Sequential Communicating Processes},
   year = {2018},
}
@inproceedings{Brolos2021,
   abstract = {Occam is a programming language built on CSP, which for many years has been used for writing safety-critical systems used in space technology and at CERN among others. However, the language has not been developed or maintained for the last 25 years, which makes it difficult to maintain the programs which currently has a code base in Occam. As changing the entire code base for such systems will prove both expensive and time consuming, it is desirable to find an easy and secure way to translate Occam programs into another programming language.This paper lays the foundation of a transpiler from Occam to the newer programming language Go using Haskell. Go is a modern programming language which also implements many of the CSP principles found in Occam, making it a suitable target.The transpiler is implemented for a subset of Occam including only basic functionality, and is successful in translating simple programs from Occam to Go, showing that it is indeed possible to automatically translate Occam programs into Go.},
   author = {Matilde Brolos and Carl Johannes Johnsen and Kenneth Skovhede},
   doi = {10.1109/COPA51043.2021.9541431},
   isbn = {9781728166834},
   booktitle = {Proceedings - 2021 Concurrent Processes Architectures and Embedded Systems Conference, COPA 2021},
   keywords = {CSP,Go,Occam,transpiler},
   month = {4},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Occam to Go translator},
   year = {2021},
}
@book{Juric2024,
   author = {Saša Jurić and Francesco Cesarini},
   isbn = {9781633438514},
   pmid = {9781633438514},
   title = {Elixir in Action, Third Edition},
   year = {2024},
}
@misc{Polato2014,
   abstract = {Context: In recent years, the valuable knowledge that can be retrieved from petabyte scale datasets - known as Big Data - led to the development of solutions to process information based on parallel and distributed computing. Lately, Apache Hadoop has attracted strong attention due to its applicability to Big Data processing. Problem: The support of Hadoop by the research community has provided the development of new features to the framework. Recently, the number of publications in journals and conferences about Hadoop has increased consistently, which makes it difficult for researchers to comprehend the full body of research and areas that require further investigation. Solution: We conducted a systematic literature review to assess research contributions to Apache Hadoop. Our objective was to identify gaps, providing motivation for new research, and outline collaborations to Apache Hadoop and its ecosystem, classifying and quantifying the main topics addressed in the literature. Results: Our analysis led to some relevant conclusions: many interesting solutions developed in the studies were never incorporated into the framework; most publications lack sufficient formal documentation of the experiments conducted by authors, hindering their reproducibility; finally, the systematic review presented in this paper demonstrates that Hadoop has evolved into a solid platform to process large datasets, but we were able to spot promising areas and suggest topics for future research within the framework. © 2014 Elsevier Ltd.},
   author = {Ivanilton Polato and Reginaldo Ré and Alfredo Goldman and Fabio Kon},
   doi = {10.1016/j.jnca.2014.07.022},
   issn = {10958592},
   journal = {Journal of Network and Computer Applications},
   keywords = {Apache Hadoop,HDFS,MapReduce,Survey,Systematic literature review},
   pages = {1-25},
   publisher = {Academic Press},
   title = {A comprehensive view of Hadoop research - A systematic literature review},
   volume = {46},
   year = {2014},
}
@inbook{Guidi2017,
   abstract = {Microservices is an emerging development paradigm where software is obtained by composing autonomous entities, called (micro)services. However, microservice systems are currently developed using general-purpose programming languages that do not provide dedicated abstractions for service composition. Instead, current practice is focused on the deployment aspects of microservices, in particular by using containerization. In this chapter, we make the case for a language-based approach to the engineering ofmicroservice architectures,which we believe is complementary to current practice. We discuss the approach in general, and then we instantiate it in terms of the Jolie programming language.},
   author = {Claudio Guidi and Ivan Lanese and Manuel Mazzara and Fabrizio Montesi},
   doi = {10.1007/978-3-319-67425-4_13},
   isbn = {9783319674254},
   journal = {Present and Ulterior Software Engineering},
   month = {11},
   pages = {217-225},
   publisher = {Springer International Publishing},
   title = {Microservices: A language-based approach},
   year = {2017},
}
@inproceedings{Howard2020,
   abstract = {Distributed consensus is a fundamental primitive for constructing fault-tolerant, strongly-consistent distributed systems. Though many distributed consensus algorithms have been proposed, just two dominate production systems: Paxos, the traditional, famously subtle, algorithm; and Raft, a more recent algorithm positioned as a more understandable alternative to Paxos. In this paper, we consider the question of which algorithm, Paxos or Raft, is the better solution to distributed consensus? We analyse both to determine exactly how they differ by describing a simplified Paxos algorithm using Raft’s terminology and pragmatic abstractions. We find that both Paxos and Raft take a very similar approach to distributed consensus, differing only in their approach to leader election. Most notably, Raft only allows servers with up-to-date logs to become leaders, whereas Paxos allows any server to be leader provided it then updates its log to ensure it is up-to-date. Raft’s approach is surprisingly efficient given its simplicity as, unlike Paxos, it does not require log entries to be exchanged during leader election. We surmise that much of the understandability of Raft comes from the paper’s clear presentation rather than being fundamental to the underlying algorithm being presented.},
   author = {Heidi Howard and Richard Mortier},
   doi = {10.1145/3380787.3393681},
   isbn = {9781450375245},
   booktitle = {Proceedings of the 7th Workshop on Principles and Practice of Consistency for Distributed Data, PaPoC 2020},
   keywords = {Distributed consensus,Paxos,Raft,State machine replication},
   month = {4},
   publisher = {Association for Computing Machinery, Inc},
   title = {Paxos vs Raft: Have we reached consensus on distributed consensus?},
   year = {2020},
}
